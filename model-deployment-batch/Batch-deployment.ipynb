{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1692291618556
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: azure-ai-ml\n",
            "Version: 1.9.0\n",
            "Summary: Microsoft Azure Machine Learning Client Library for Python\n",
            "Home-page: https://github.com/Azure/azure-sdk-for-python\n",
            "Author: Microsoft Corporation\n",
            "Author-email: azuresdkengsysadmins@microsoft.com\n",
            "License: MIT License\n",
            "Location: /anaconda/envs/azureml_py38/lib/python3.8/site-packages\n",
            "Requires: strictyaml, azure-storage-file-share, azure-storage-blob, azure-core, opencensus-ext-azure, pydash, tqdm, jsonschema, azure-storage-file-datalake, pyyaml, typing-extensions, msrest, pyjwt, marshmallow, colorama, azure-common, azure-mgmt-core, isodate\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "# checking Python SDKv2\n",
        "!pip show azure-ai-ml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1692291638686
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1692291653074
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: /config.json\n"
          ]
        }
      ],
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Train a model and dump it for scoring later\n",
        "The following part trains a simple model and dump it in a directory as a pickle file in the `model` folder. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692292627613
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Open terminal and move to the src folder and run to save the model\n",
        "!python train-model-parameters.py --training_data diabetes.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Register the custom model\n",
        "\n",
        "Batch deployments can only deploy models registered in the workspace. You'll register an custom model, which is stored in the local `model` folder.\n",
        "\n",
        "https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-model-custom-output?view=azureml-api-2&tabs=python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient, Input, load_component\n",
        "from azure.ai.ml.entities import BatchEndpoint, ModelBatchDeployment, ModelBatchDeploymentSettings, PipelineComponentBatchDeployment, Model, AmlCompute, Data, BatchRetrySettings, CodeConfiguration, Environment, Data\n",
        "from azure.ai.ml.constants import AssetTypes, BatchDeploymentOutputAction\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "from azure.identity import DefaultAzureCredential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Registering the model\n",
        "# Batch Endpoint can only deploy registered models. In this case, we already have a local copy of the model in the repository, \n",
        "# so we only need to publish the model to the registry in the workspace. You can skip this step if the model you are trying to deploy is already registered.\n",
        "\n",
        "\n",
        "model_name = \"model\"\n",
        "model_description = \"A linear classifier.\"\n",
        "model_local_path = \"src/model/\"\n",
        "\n",
        "model = ml_client.models.create_or_update(\n",
        "    Model(\n",
        "        name=model_name,\n",
        "        path=model_local_path,\n",
        "        type=AssetTypes.CUSTOM_MODEL,\n",
        "        tags={\"framework\": \"scikit-learn\", \"estimator\": \"LogisticRegression\"},\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a scoring script\n",
        "\n",
        "We need to create a scoring script that can read the input data provided by the batch deployment and return the scores of the model. We are also going to write directly to the output folder of the job. In summary, the proposed scoring script does as follows:\n",
        "\n",
        "- Reads the input data as CSV files.\n",
        "- Runs an MLflow model predict function over the input data.\n",
        "- Appends the predictions to a pandas.DataFrame along with the input data.\n",
        "- Writes the data in a file named as the input file, but in parquet format.\n",
        "\n",
        "### Remarks:\n",
        "\n",
        "- Notice how the environment variable AZUREML_BI_OUTPUT_PATH is used to get access to the output path of the deployment job.\n",
        "    - In Azure Machine Learning Studio, the environment variable AZUREML_BI_OUTPUT_PATH is used in the context of batch inferencing. It points to the location where the output results of the batch inferencing should be written.\n",
        "- The init() function is populating a global variable called output_path that can be used later to know where to write.\n",
        "- The run method returns a list of the processed files. It is required for the run function to return a list or a pandas.DataFrame object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/model/score.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/model/score.py\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import glob\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    global output_path\n",
        "\n",
        "    # AZUREML_MODEL_DIR is an environment variable created during deployment\n",
        "    # It is the path to the model folder\n",
        "    # Please provide your model's folder name if there's one:\n",
        "    output_path = os.environ[\"AZUREML_BI_OUTPUT_PATH\"]\n",
        "    model_path = os.environ[\"AZUREML_MODEL_DIR\"]\n",
        "    model_file = glob.glob(f\"{model_path}/*/*.pkl\")[-1]\n",
        "\n",
        "    with open(model_file, \"rb\") as file:\n",
        "        model = pickle.load(file)\n",
        "\n",
        "\n",
        "def run(mini_batch: List[str]):\n",
        "    for file_path in mini_batch:\n",
        "        data = pd.read_csv(file_path)\n",
        "        X = data[['Pregnancies',\n",
        "            'PlasmaGlucose',\n",
        "            'DiastolicBloodPressure',\n",
        "            'TricepsThickness',\n",
        "            'SerumInsulin',\n",
        "            'BMI',\n",
        "            'DiabetesPedigree',\n",
        "            'Age']].values\n",
        "\n",
        "        pred = model.predict(X)\n",
        "\n",
        "\n",
        "        data[\"prediction\"] = pred\n",
        "\n",
        "        output_file_name = Path(file_path).stem + '_pred'\n",
        "        output_file_path = os.path.join(output_path, output_file_name + \".parquet\")\n",
        "        data.to_parquet(output_file_path)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/home/azureuser/cloudfiles/code/my-azure-ml-projects/model-deployment-batch/data/diabetes.csv']\n",
            "['/home/azureuser/cloudfiles/code/my-azure-ml-projects/model-deployment-batch/data/diabetes.csv']\n",
            "[0 0 0 ... 1 0 1]\n"
          ]
        }
      ],
      "source": [
        "### TEST the scoring script to check whether it works\n",
        "\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import glob\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    global output_path\n",
        "\n",
        "    # Replace with local paths for debugging\n",
        "    output_path = \"/home/azureuser/cloudfiles/code/my-azure-ml-projects/model-deployment-batch/data/\"\n",
        "    model_path = \"/home/azureuser/cloudfiles/code/my-azure-ml-projects/model-deployment-batch/src/model/\"\n",
        "    model_file = glob.glob(f\"{model_path}/*.pkl\")[-1]\n",
        "\n",
        "    with open(model_file, \"rb\") as file:\n",
        "        model = pickle.load(file)\n",
        "\n",
        "\n",
        "def run(mini_batch: List[str]):\n",
        "    print(mini_batch)\n",
        "    for file_path in mini_batch:\n",
        "        data = pd.read_csv(file_path)\n",
        "        X = data[['Pregnancies',\n",
        "                'PlasmaGlucose',\n",
        "                'DiastolicBloodPressure',\n",
        "                'TricepsThickness',\n",
        "                'SerumInsulin',\n",
        "                'BMI',\n",
        "                'DiabetesPedigree',\n",
        "                'Age']].values\n",
        "\n",
        "        pred = model.predict(X)\n",
        "\n",
        "        data[\"prediction\"] = pred\n",
        "        print(pred)\n",
        "\n",
        "        output_file_name = Path(file_path).stem + '_pred'\n",
        "        output_file_path = os.path.join(output_path, output_file_name + \".parquet\")\n",
        "        data.to_parquet(output_file_path)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "# Add this code to run the script locally\n",
        "if __name__ == \"__main__\":\n",
        "    init()   \n",
        "    test_files = glob.glob(\"/home/azureuser/cloudfiles/code/my-azure-ml-projects/model-deployment-batch/data/*.csv\")\n",
        "    print(test_files)\n",
        "    run(test_files)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a Custom Environement\n",
        "\n",
        "** Note that, __for custom model__, it seesm that only custom environment needs to be deployed and the existing one can not be used (personal experience). ***\n",
        "\n",
        "Your deployment requires an execution environment in which to run the scoring script. Any dependency your code requires should be included in the environment.\n",
        "\n",
        "You can create an environment with a Docker image with Conda dependencies, or with a Dockerfile.\n",
        "\n",
        "You'll also need to add the library azureml-core as it is required for batch deployments to work.\n",
        "\n",
        "To create an environment using a base Docker image, you can define the Conda dependencies in a conda.yaml file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/model/conda-env.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile 'src/model/conda-env.yml'\n",
        "\n",
        "name: basic-env-cpu\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.8\n",
        "  - pandas\n",
        "  - scikit-learn\n",
        "  - numpy\n",
        "  - matplotlib\n",
        "  - pip:\n",
        "      - azureml-core\n",
        "      - mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Environment({'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'FarbodTaymouri-env-batch', 'description': 'Environment created from a Docker image plus Conda environment.', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourceGroups/mlcertificate1/providers/Microsoft.MachineLearningServices/workspaces/ft_ml2/environments/FarbodTaymouri-env-batch/versions/1', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/farbodtaymouri2/code/my-azure-ml-projects/model-deployment-batch', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f3da45492d0>, 'serialize': <msrest.serialization.Serializer object at 0x7f3da454b2e0>, 'version': '1', 'latest_version': None, 'conda_file': {'channels': ['conda-forge'], 'dependencies': ['python=3.8', 'pandas', 'scikit-learn', 'numpy', 'matplotlib', {'pip': ['azureml-core', 'mlflow']}], 'name': 'basic-env-cpu'}, 'image': 'mcr.microsoft.com/azureml/minimal-ubuntu18.04-py37-cpu-inference:latest', 'build': None, 'inference_config': None, 'os_type': 'Linux', 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': '{\\n  \"channels\": [\\n    \"conda-forge\"\\n  ],\\n  \"dependencies\": [\\n    \"python=3.8\",\\n    \"pandas\",\\n    \"scikit-learn\",\\n    \"numpy\",\\n    \"matplotlib\",\\n    {\\n      \"pip\": [\\n        \"azureml-core\",\\n        \"mlflow\"\\n      ]\\n    }\\n  ],\\n  \"name\": \"basic-env-cpu\"\\n}'})"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "env = Environment(\n",
        "    image=\"mcr.microsoft.com/azureml/minimal-ubuntu18.04-py37-cpu-inference:latest\",   # Double check this as it might fail the creation of image!!!!!\n",
        "    conda_file=\"./src/model/conda-env.yml\",\n",
        "    name=\"FarbodTaymouri-env-batch\",\n",
        "    description=\"Environment created from a Docker image plus Conda environment.\",\n",
        ")\n",
        "ml_client.environments.create_or_update(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check the custom envrionment to see it works\n",
        "https://learn.microsoft.com/en-us/azure/machine-learning/migrate-to-v2-local-runs?view=azureml-api-2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/model/sample_script.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/model/sample_script.py\n",
        "\n",
        "# Sample script to run in the custom environment\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "import glob\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "print(sys.version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: /config.json\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>model-deployment-batch</td><td>frosty_ticket_qkxnp151lv</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/frosty_ticket_qkxnp151lv?wsid=/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourcegroups/mlcertificate1/workspaces/ft_ml2&amp;tid=71f8feea-4caa-4230-a785-dca61147bceb\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
            ],
            "text/plain": [
              "Command({'parameters': {}, 'init': False, 'name': 'frosty_ticket_qkxnp151lv', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/farbodtaymouri/my-azure-ml-projects.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': 'b190502e2e914cc24e649648c04141c89f4661d0', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain', 'ContentSnapshotId': 'c9026cf1-42f8-4b86-859d-5ac280561a07'}, 'print_as_yaml': True, 'id': '/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourceGroups/mlcertificate1/providers/Microsoft.MachineLearningServices/workspaces/ft_ml2/jobs/frosty_ticket_qkxnp151lv', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/farbodtaymouri2/code/my-azure-ml-projects/model-deployment-batch', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f8e6528e2f0>, 'serialize': <msrest.serialization.Serializer object at 0x7f8e6528c790>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'frosty_ticket_qkxnp151lv', 'experiment_name': 'model-deployment-batch', 'compute': 'farbodCluster', 'services': {'Tracking': {'endpoint': 'azureml://australiaeast.api.azureml.ms/mlflow/v1.0/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourceGroups/mlcertificate1/providers/Microsoft.MachineLearningServices/workspaces/ft_ml2?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/frosty_ticket_qkxnp151lv?wsid=/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourcegroups/mlcertificate1/workspaces/ft_ml2&tid=71f8feea-4caa-4230-a785-dca61147bceb', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.frosty_ticket_qkxnp151lv', 'mode': 'rw_mount'}}, 'inputs': {}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f8e6528d9f0>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'frosty_ticket_qkxnp151lv', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('.'), 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f8e6528e2f0>, 'serialize': <msrest.serialization.Serializer object at 0x7f8e6528d7b0>, 'command': 'python sample_script.py', 'code': '/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourceGroups/mlcertificate1/providers/Microsoft.MachineLearningServices/workspaces/ft_ml2/codes/db587344-88f0-451c-938a-3aec0532c31c/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourceGroups/mlcertificate1/providers/Microsoft.MachineLearningServices/workspaces/ft_ml2/environments/FarbodTaymouri-env-batch/versions/1', 'distribution': None, 'resources': None, 'queue_settings': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'frosty_ticket_qkxnp151lv', 'is_deterministic': True, 'inputs': {}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.frosty_ticket_qkxnp151lv', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': [], 'CommandComponent__additional_includes_obj': None}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://australiaeast.api.azureml.ms/mlflow/v1.0/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourceGroups/mlcertificate1/providers/Microsoft.MachineLearningServices/workspaces/ft_ml2?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/frosty_ticket_qkxnp151lv?wsid=/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourcegroups/mlcertificate1/workspaces/ft_ml2&tid=71f8feea-4caa-4230-a785-dca61147bceb', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f8e6528e2f0>}, 'instance_id': '03d5e9fb-58b1-450e-bcd2-fd7398ed05a1', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'FarbodTaymouri-env-batch:1', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#import required libraries\n",
        "from azure.ai.ml import MLClient, command\n",
        "from azure.ai.ml.entities import Environment\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)\n",
        "\n",
        "\n",
        "# define the command\n",
        "command_job = command(\n",
        "    code='./src/model',\n",
        "    command='python sample_script.py',\n",
        "    # inputs={\n",
        "    # \"diabetes_data\": Input(\n",
        "    #     type=AssetTypes.URI_FILE, \n",
        "    #     path=\"azureml:diabetes-local:1\"\n",
        "    #     )\n",
        "    # },\n",
        "    environment='FarbodTaymouri-env-batch@latest',\n",
        "    compute='farbodCluster',   # Local mode doesn't work\n",
        ")\n",
        "\n",
        "returned_job = ml_client.jobs.create_or_update(command_job)\n",
        "returned_job"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a batch endpoint\n",
        "\n",
        "A batch endpoint is an HTTPS endpoint that applications can call to trigger a batch scoring job. A batch endpoint name needs to be unique within an Azure region. You'll use the `datetime` function to generate a unique name based on the current date and time. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'batch-09071159919380'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import datetime\n",
        "\n",
        "endpoint_name = \"batch-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
        "endpoint_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<azure.core.polling._poller.LROPoller at 0x7f8f062d31c0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azure.ai.ml.entities import BatchEndpoint\n",
        "\n",
        "# create a batch endpoint\n",
        "endpoint = BatchEndpoint(\n",
        "    name=endpoint_name,\n",
        "    description=\"A batch endpoint for classifying diabetes in patients\",\n",
        ")\n",
        "\n",
        "ml_client.batch_endpoints.begin_create_or_update(endpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANT! Wait until the endpoint is created before continuing! A green notification should appear in the studio. </p>\n",
        "\n",
        "## Create the deployment\n",
        "\n",
        "A deployment is a set of resources required for hosting the model that does the actual inferencing. We will create a deployment for our endpoint using the `BatchDeployment` class. \n",
        "\n",
        "Since you're deploying an MLflow model, you don't need a scoring script or define the environment. Azure Machine Learning will automatically create those assets for you. The `MLmodel` file in the `model` folder is used to understand what the expected inputs and outputs are of the model.\n",
        "\n",
        "You'll deploy a model with the following parameters:\n",
        "\n",
        "- `name`: Name of the deployment.\n",
        "- `description`: Optional description to further clarify what the deployment represents.\n",
        "- `endpoint_name`: Name of the previously created endpoint the model should be deployed to.\n",
        "- `model`: Name of the registered model.\n",
        "- `compute`: Compute to be used when invoking the deployed model to generate predictions.\n",
        "- `instance_count`: Count of compute nodes to use for generating predictions.\n",
        "- `max_concurrency_per_instance`: Maximum number of parallel scoring script runs per compute node.\n",
        "- `mini_batch_size`: Number of files passed per scoring script run.\n",
        "-- How does parallelization work?:\n",
        "    Batch deployments distribute work at the file level, which means that a folder containing 100 files with mini-batches of 10 files will generate 10 batches of 10 files each. Notice that this will happen regardless of the size of the files involved. If your files are too big to be processed in large mini-batches we suggest to either split the files in smaller files to achieve a higher level of parallelism or to decrease the number of files per mini-batch. At this moment, batch deployment can't account for skews in the file's size distribution.\n",
        "- `output_action`: Each new prediction will be appended as a new row to the output file.\n",
        "- `output_file_name`: File to which predictions will be appended.\n",
        "- `retry_settings`: Settings for a mini-batch fails.\n",
        "- `logging_level`: The log verbosity level. Allowed values are `warning`, `info`, and `debug`. \n",
        "\n",
        "Running the following cell will configure and create the deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FarbodTaymouri-env-batch\n",
            "batch-inference-ncd-env\n",
            "DefaultNcdEnv-openmpi4-1-0-ubuntu20-04\n",
            "farbod-deployment-environment\n",
            "deployment-environment\n",
            "DefaultNcdEnv-mlflow-ubuntu20-04-py38-cpu-inference\n",
            "AzureML-AI-Studio-Development\n",
            "AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu\n",
            "AzureML-ACPT-pytorch-1.12-py38-cuda11.6-gpu\n",
            "AzureML-ACPT-pytorch-1.12-py39-cuda11.6-gpu\n",
            "AzureML-ACPT-pytorch-1.11-py38-cuda11.5-gpu\n",
            "AzureML-ACPT-pytorch-1.11-py38-cuda11.3-gpu\n",
            "AzureML-responsibleai-0.21-ubuntu20.04-py38-cpu\n",
            "AzureML-responsibleai-0.20-ubuntu20.04-py38-cpu\n",
            "AzureML-tensorflow-2.5-ubuntu20.04-py38-cuda11-gpu\n",
            "AzureML-tensorflow-2.6-ubuntu20.04-py38-cuda11-gpu\n",
            "AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu\n",
            "AzureML-sklearn-1.0-ubuntu20.04-py38-cpu\n",
            "AzureML-pytorch-1.10-ubuntu18.04-py38-cuda11-gpu\n",
            "AzureML-pytorch-1.9-ubuntu18.04-py37-cuda11-gpu\n",
            "AzureML-pytorch-1.8-ubuntu18.04-py37-cuda11-gpu\n",
            "AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\n",
            "AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu\n",
            "AzureML-pytorch-1.7-ubuntu18.04-py37-cuda11-gpu\n",
            "AzureML-tensorflow-2.4-ubuntu18.04-py37-cuda11-gpu\n",
            "AzureML-Triton\n",
            "AzureML-Designer-Score\n",
            "AzureML-VowpalWabbit-8.8.0\n",
            "AzureML-PyTorch-1.3-CPU\n"
          ]
        }
      ],
      "source": [
        "# See whether the enviornment is avaialble\n",
        "envs = ml_client.environments.list()\n",
        "for my_env in envs:\n",
        "    print(my_env.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "deployment = ModelBatchDeployment(\n",
        "    name=\"classifier-lm-custom\",\n",
        "    description=\"a linear model classifier for predicting diabetes\",\n",
        "    endpoint_name=endpoint.name,\n",
        "    model=model,\n",
        "    # environment= env,\n",
        "    environment = 'FarbodTaymouri-env-batch@latest',\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code=\"./src/model\",\n",
        "        scoring_script=\"score.py\",\n",
        "    ),\n",
        "    compute='farbodCluster',\n",
        "    settings=ModelBatchDeploymentSettings(\n",
        "        mini_batch_size=1,\n",
        "        instance_count=2,\n",
        "        max_concurrency_per_instance=2,\n",
        "        output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
        "        output_file_name=\"predictions.csv\",\n",
        "        retry_settings=BatchRetrySettings(max_retries=1, timeout=100),\n",
        "        logging_level=\"info\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<azure.core.polling._poller.LROPoller at 0x7f8e697a94b0>"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.batch_deployments.begin_create_or_update(deployment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANT! Wait until the default deployment is set before continuing! A green notification should appear in the studio. </p>\n",
        "\n",
        "## Prepare the data for batch predictions\n",
        "\n",
        "In the `data` folder you'll find CSV files with unlabeled data. You'll create a data asset that points to the files in the `data` folder, which you'll use as input for the batch job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mUploading unlabled-data (0.02 MBs): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17119/17119 [00:00<00:00, 85250.06it/s]\u001b[0m\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Data({'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_folder', 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'patient-data-unlabeled', 'description': 'An unlabeled dataset for diabetes classification', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourceGroups/mlcertificate1/providers/Microsoft.MachineLearningServices/workspaces/ft_ml2/data/patient-data-unlabeled/versions/7', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/farbodtaymouri2/code/my-azure-ml-projects/model-deployment-batch', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f8ecc72b2e0>, 'serialize': <msrest.serialization.Serializer object at 0x7f8e832a3940>, 'version': '7', 'latest_version': None, 'path': 'azureml://subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourcegroups/mlcertificate1/workspaces/ft_ml2/datastores/workspaceblobstore/paths/LocalUpload/4badec4dfe88902995b0ba1a67686a00/unlabled-data/', 'datastore': None})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "data_path = \"./unlabled-data\"\n",
        "dataset_name = \"patient-data-unlabeled\"\n",
        "\n",
        "patient_dataset_unlabeled = Data(\n",
        "    path=data_path,\n",
        "    type=AssetTypes.URI_FOLDER,\n",
        "    description=\"An unlabeled dataset for diabetes classification\",\n",
        "    name=dataset_name,\n",
        ")\n",
        "ml_client.data.create_or_update(patient_dataset_unlabeled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Data({'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_folder', 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'patient-data-unlabeled', 'description': 'An unlabeled dataset for diabetes classification', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourceGroups/mlcertificate1/providers/Microsoft.MachineLearningServices/workspaces/ft_ml2/data/patient-data-unlabeled/versions/7', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/farbodtaymouri2/code/my-azure-ml-projects/model-deployment-batch', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f8e6528fa00>, 'serialize': <msrest.serialization.Serializer object at 0x7f8e650ecf40>, 'version': '7', 'latest_version': None, 'path': 'azureml://subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourcegroups/mlcertificate1/workspaces/ft_ml2/datastores/workspaceblobstore/paths/LocalUpload/4badec4dfe88902995b0ba1a67686a00/unlabled-data/', 'datastore': None})"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "my_path = './data/diabetes.csv'\n",
        "\n",
        "patient_dataset_unlabeleda = Data(\n",
        "    path=my_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"Data asset pointing to a local file, automatically uploaded to the default datastore\",\n",
        "    name=\"diabetes-local\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(patient_dataset_unlabeled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reading the dataset\n",
        "patient_dataset_unlabeled = ml_client.data.get(\n",
        "    name=\"patient-data-unlabeled\", label=\"latest\"\n",
        ")\n",
        "\n",
        "# # Read the data from data asset and print it\n",
        "# import pandas as pd\n",
        "# pd.read_csv(patient_dataset_unlabeled.path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submit the job\n",
        "\n",
        "Now that you have deployed a model to a batch endpoint, and have an unlabeled data asset, you're ready to invoke the endpoint to generate predictions on the unlabeled data.\n",
        "\n",
        "First, you'll define the input by referring to the registered data asset. Then, you'll invoke the endpoint, which will submit a pipeline job. You can use the job URL to monitor it in the Studio. The job will contain a child job that represents the running of the (generated) scoring script to get the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "input = Input(type=AssetTypes.URI_FOLDER, path=patient_dataset_unlabeled.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>batch-09071159919380</td><td>batchjob-6462b5aa-cb56-4283-ab2d-f4725c08fe4d</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/batchjob-6462b5aa-cb56-4283-ab2d-f4725c08fe4d?wsid=/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourcegroups/mlcertificate1/workspaces/ft_ml2&amp;tid=71f8feea-4caa-4230-a785-dca61147bceb\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
            ],
            "text/plain": [
              "PipelineJob({'inputs': {}, 'outputs': {}, 'jobs': {}, 'component': PipelineComponent({'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'auto_delete_setting': None, 'name': 'azureml_anonymous', 'description': \"Attempting to create pipeline submission settings for endpoint: 'batch-09071159919380', deployment: 'classifier-lm-custom'.\", 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/farbodtaymouri2/code/my-azure-ml-projects/model-deployment-batch', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f8e650ec3a0>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline', 'display_name': 'mango_fowl_lrscwwtf', 'is_deterministic': None, 'inputs': {}, 'outputs': {}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {}, 'job_types': {}, 'job_sources': {}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'batchjob-6462b5aa-cb56-4283-ab2d-f4725c08fe4d', 'description': \"Attempting to create pipeline submission settings for endpoint: 'batch-09071159919380', deployment: 'classifier-lm-custom'.\", 'tags': {'outputType': 'output_data', 'output_data_name': None, 'inputType': 'input_data', 'azureml.batchrun': 'true', 'azureml.deploymentname': 'classifier-lm-custom', 'azureml.jobtype': 'azureml.batchjob'}, 'properties': {'azureml.pipelineid': '6a8214ff-928b-4fec-baf5-a7af8315247e', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{\"run_max_try\":\"1\",\"run_invocation_timeout\":\"100\",\"mini_batch_size\":\"1\",\"error_threshold\":\"-1\",\"logging_level\":\"INFO\",\"process_count_per_node\":\"2\",\"NodeCount\":\"1\",\"append_row_file_name\":\"predictions.csv\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'False', 'azureml.pipelineComponent': 'pipelinerun'}, 'print_as_yaml': True, 'id': '/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourceGroups/mlcertificate1/providers/Microsoft.MachineLearningServices/workspaces/ft_ml2/jobs/batchjob-6462b5aa-cb56-4283-ab2d-f4725c08fe4d', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/farbodtaymouri2/code/my-azure-ml-projects/model-deployment-batch', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f8e650ec220>, 'serialize': <msrest.serialization.Serializer object at 0x7f8e650ec160>, 'display_name': 'mango_fowl_lrscwwtf', 'experiment_name': 'batch-09071159919380', 'compute': None, 'services': {'Tracking': {'endpoint': 'azureml://australiaeast.api.azureml.ms/mlflow/v1.0/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourceGroups/mlcertificate1/providers/Microsoft.MachineLearningServices/workspaces/ft_ml2?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/batchjob-6462b5aa-cb56-4283-ab2d-f4725c08fe4d?wsid=/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourcegroups/mlcertificate1/workspaces/ft_ml2&tid=71f8feea-4caa-4230-a785-dca61147bceb', 'type': 'Studio'}}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "job = ml_client.batch_endpoints.invoke(\n",
        "    endpoint_name=endpoint.name, \n",
        "    deployment_name=deployment.name,\n",
        "    input=input)\n",
        "\n",
        "ml_client.jobs.get(job.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get the results\n",
        "\n",
        "When the pipeline job that invokes the batch endpoint is completed, you can view the results. All predictions are collected in the `predictions.csv` file that is stored in the default datastore. You can download the file and visualize the data by running the following cells. \n",
        "\n",
        "The job generates a named output called `score` where all the generated files are placed. Since we wrote into the directory directly, one file per each input file, then we can expect to have the same number of files. In this particular example we decided to name the output files the same as the inputs, but they will have a parquet extension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_client.jobs.download(name=job.name, download_path=\".\", output_name=\"score\")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
