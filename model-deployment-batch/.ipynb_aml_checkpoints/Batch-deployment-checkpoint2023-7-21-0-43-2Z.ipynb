{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1692291618556
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: azure-ai-ml\n",
            "Version: 1.9.0\n",
            "Summary: Microsoft Azure Machine Learning Client Library for Python\n",
            "Home-page: https://github.com/Azure/azure-sdk-for-python\n",
            "Author: Microsoft Corporation\n",
            "Author-email: azuresdkengsysadmins@microsoft.com\n",
            "License: MIT License\n",
            "Location: /anaconda/envs/azureml_py38/lib/python3.8/site-packages\n",
            "Requires: msrest, azure-common, tqdm, isodate, marshmallow, pyyaml, typing-extensions, jsonschema, azure-mgmt-core, strictyaml, pyjwt, pydash, opencensus-ext-azure, azure-storage-file-datalake, azure-core, azure-storage-file-share, azure-storage-blob, colorama\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "# checking Python SDKv2\n",
        "!pip show azure-ai-ml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1692291638686
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1692291653074
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: /config.json\n"
          ]
        }
      ],
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Train a model and dump it for scoring later\n",
        "The following part trains a simple model and dump it in a directory as a pickle file in the `model` folder. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692292627613
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Open terminal and move to the src folder and run to save the model\n",
        "!python train-model-parameters.py --training_data diabetes.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Register the custom model\n",
        "\n",
        "Batch deployments can only deploy models registered in the workspace. You'll register an custom model, which is stored in the local `model` folder.\n",
        "\n",
        "https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-model-custom-output?view=azureml-api-2&tabs=python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient, Input, load_component\n",
        "from azure.ai.ml.entities import BatchEndpoint, ModelBatchDeployment, ModelBatchDeploymentSettings, PipelineComponentBatchDeployment, Model, AmlCompute, Data, BatchRetrySettings, CodeConfiguration, Environment, Data\n",
        "from azure.ai.ml.constants import AssetTypes, BatchDeploymentOutputAction\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "from azure.identity import DefaultAzureCredential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Registering the model\n",
        "# Batch Endpoint can only deploy registered models. In this case, we already have a local copy of the model in the repository, \n",
        "# so we only need to publish the model to the registry in the workspace. You can skip this step if the model you are trying to deploy is already registered.\n",
        "\n",
        "\n",
        "model_name = \"model\"\n",
        "model_description = \"A linear classifier.\"\n",
        "model_local_path = \"src/model/\"\n",
        "\n",
        "model = ml_client.models.create_or_update(\n",
        "    Model(\n",
        "        name=model_name,\n",
        "        path=model_local_path,\n",
        "        type=AssetTypes.CUSTOM_MODEL,\n",
        "        tags={\"framework\": \"scikit-learn\", \"estimator\": \"LG\"},\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a scoring script\n",
        "\n",
        "We need to create a scoring script that can read the input data provided by the batch deployment and return the scores of the model. We are also going to write directly to the output folder of the job. In summary, the proposed scoring script does as follows:\n",
        "\n",
        "- Reads the input data as CSV files.\n",
        "- Runs an MLflow model predict function over the input data.\n",
        "- Appends the predictions to a pandas.DataFrame along with the input data.\n",
        "- Writes the data in a file named as the input file, but in parquet format.\n",
        "\n",
        "### Remarks:\n",
        "\n",
        "- Notice how the environment variable AZUREML_BI_OUTPUT_PATH is used to get access to the output path of the deployment job.\n",
        "    - In Azure Machine Learning Studio, the environment variable AZUREML_BI_OUTPUT_PATH is used in the context of batch inferencing. It points to the location where the output results of the batch inferencing should be written.\n",
        "- The init() function is populating a global variable called output_path that can be used later to know where to write.\n",
        "- The run method returns a list of the processed files. It is required for the run function to return a list or a pandas.DataFrame object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing src/model/score.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/model/score.py\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import glob\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    global output_path\n",
        "\n",
        "    # AZUREML_MODEL_DIR is an environment variable created during deployment\n",
        "    # It is the path to the model folder\n",
        "    # Please provide your model's folder name if there's one:\n",
        "    output_path = os.environ[\"AZUREML_BI_OUTPUT_PATH\"]\n",
        "    model_path = os.environ[\"AZUREML_MODEL_DIR\"]\n",
        "    model_file = glob.glob(f\"{model_path}/*/*.pkl\")[-1]\n",
        "\n",
        "    with open(model_file, \"rb\") as file:\n",
        "        model = pickle.load(file)\n",
        "\n",
        "\n",
        "def run(mini_batch: List[str]):\n",
        "    for file_path in mini_batch:\n",
        "        data = pd.read_csv(file_path)\n",
        "        pred = model.predict(data)\n",
        "\n",
        "        data[\"prediction\"] = pred\n",
        "\n",
        "        output_file_name = Path(file_path).stem\n",
        "        output_file_path = os.path.join(output_path, output_file_name + \".parquet\")\n",
        "        data.to_parquet(output_file_path)\n",
        "\n",
        "    return mini_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a batch endpoint\n",
        "\n",
        "A batch endpoint is an HTTPS endpoint that applications can call to trigger a batch scoring job. A batch endpoint name needs to be unique within an Azure region. You'll use the `datetime` function to generate a unique name based on the current date and time. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'batch-08171837639158'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import datetime\n",
        "\n",
        "endpoint_name = \"batch-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
        "endpoint_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<azure.core.polling._poller.LROPoller at 0x7f0c96465390>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azure.ai.ml.entities import BatchEndpoint\n",
        "\n",
        "# create a batch endpoint\n",
        "endpoint = BatchEndpoint(\n",
        "    name=endpoint_name,\n",
        "    description=\"A batch endpoint for classifying diabetes in patients\",\n",
        ")\n",
        "\n",
        "ml_client.batch_endpoints.begin_create_or_update(endpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANT! Wait until the endpoint is created before continuing! A green notification should appear in the studio. </p>\n",
        "\n",
        "## Create the deployment\n",
        "\n",
        "A deployment is a set of resources required for hosting the model that does the actual inferencing. We will create a deployment for our endpoint using the `BatchDeployment` class. \n",
        "\n",
        "Since you're deploying an MLflow model, you don't need a scoring script or define the environment. Azure Machine Learning will automatically create those assets for you. The `MLmodel` file in the `model` folder is used to understand what the expected inputs and outputs are of the model.\n",
        "\n",
        "You'll deploy a model with the following parameters:\n",
        "\n",
        "- `name`: Name of the deployment.\n",
        "- `description`: Optional description to further clarify what the deployment represents.\n",
        "- `endpoint_name`: Name of the previously created endpoint the model should be deployed to.\n",
        "- `model`: Name of the registered model.\n",
        "- `compute`: Compute to be used when invoking the deployed model to generate predictions.\n",
        "- `instance_count`: Count of compute nodes to use for generating predictions.\n",
        "- `max_concurrency_per_instance`: Maximum number of parallel scoring script runs per compute node.\n",
        "- `mini_batch_size`: Number of files passed per scoring script run.\n",
        "- `output_action`: Each new prediction will be appended as a new row to the output file.\n",
        "- `output_file_name`: File to which predictions will be appended.\n",
        "- `retry_settings`: Settings for a mini-batch fails.\n",
        "- `logging_level`: The log verbosity level. Allowed values are `warning`, `info`, and `debug`. \n",
        "\n",
        "Running the following cell will configure and create the deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch-inference-ncd-env\n",
            "DefaultNcdEnv-openmpi4-1-0-ubuntu20-04\n",
            "farbod-deployment-environment\n",
            "deployment-environment\n",
            "DefaultNcdEnv-mlflow-ubuntu20-04-py38-cpu-inference\n",
            "AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu\n",
            "AzureML-ACPT-pytorch-1.12-py38-cuda11.6-gpu\n",
            "AzureML-ACPT-pytorch-1.12-py39-cuda11.6-gpu\n",
            "AzureML-ACPT-pytorch-1.11-py38-cuda11.5-gpu\n",
            "AzureML-ACPT-pytorch-1.11-py38-cuda11.3-gpu\n",
            "AzureML-responsibleai-0.21-ubuntu20.04-py38-cpu\n",
            "AzureML-responsibleai-0.20-ubuntu20.04-py38-cpu\n",
            "AzureML-tensorflow-2.5-ubuntu20.04-py38-cuda11-gpu\n",
            "AzureML-tensorflow-2.6-ubuntu20.04-py38-cuda11-gpu\n",
            "AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu\n",
            "AzureML-sklearn-1.0-ubuntu20.04-py38-cpu\n",
            "AzureML-pytorch-1.10-ubuntu18.04-py38-cuda11-gpu\n",
            "AzureML-pytorch-1.9-ubuntu18.04-py37-cuda11-gpu\n",
            "AzureML-pytorch-1.8-ubuntu18.04-py37-cuda11-gpu\n",
            "AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\n",
            "AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu\n",
            "AzureML-pytorch-1.7-ubuntu18.04-py37-cuda11-gpu\n",
            "AzureML-tensorflow-2.4-ubuntu18.04-py37-cuda11-gpu\n",
            "AzureML-Triton\n",
            "AzureML-Designer-Score\n",
            "AzureML-VowpalWabbit-8.8.0\n",
            "AzureML-PyTorch-1.3-CPU\n"
          ]
        }
      ],
      "source": [
        "# See whether the enviornment is avaialble\n",
        "envs = ml_client.environments.list()\n",
        "for my_env in envs:\n",
        "    print(my_env.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "deployment = ModelBatchDeployment(\n",
        "    name=\"classifier-lm-custom\",\n",
        "    description=\"a linear model classifier for predicting diabetes\",\n",
        "    endpoint_name=endpoint.name,\n",
        "    model=model,\n",
        "    environment= 'AzureML-sklearn-0.24-ubuntu18.04-py37-cpu',\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code=\"./src/model\",\n",
        "        scoring_script=\"score.py\",\n",
        "    ),\n",
        "    compute='farbodCluster',\n",
        "    settings=ModelBatchDeploymentSettings(\n",
        "        mini_batch_size=2,\n",
        "        instance_count=2,\n",
        "        max_concurrency_per_instance=2,\n",
        "        output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
        "        output_file_name=\"predictions.csv\",\n",
        "        retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n",
        "        logging_level=\"info\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "ename": "HttpResponseError",
          "evalue": "(UserError) The Deployment request provided has the following validation errors. Please resolve them and try again.\nErrors:\n[\n  {\n    \"PropertyName\": \"ModelConfiguration.EnvironmentId\",\n    \"ErrorMessage\": \"The value specified for 'Environment Id' is not a valid ARM resource identifier.\",\n    \"AttemptedValue\": \"azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\",\n    \"ErrorCode\": \"ArgumentInvalid\"\n  }\n]\n\nCode: UserError\nMessage: The Deployment request provided has the following validation errors. Please resolve them and try again.\nErrors:\n[\n  {\n    \"PropertyName\": \"ModelConfiguration.EnvironmentId\",\n    \"ErrorMessage\": \"The value specified for 'Environment Id' is not a valid ARM resource identifier.\",\n    \"AttemptedValue\": \"azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\",\n    \"ErrorCode\": \"ArgumentInvalid\"\n  }\n]\n\nAdditional Information:Type: ComponentName\nInfo: {\n    \"value\": \"managementfrontend\"\n}Type: Correlation\nInfo: {\n    \"value\": {\n        \"operation\": \"c889250772c5672c6281eccb13f80293\",\n        \"request\": \"5fe34d5f7055c3bd\"\n    }\n}Type: Environment\nInfo: {\n    \"value\": \"australiaeast\"\n}Type: Location\nInfo: {\n    \"value\": \"australiaeast\"\n}Type: Time\nInfo: {\n    \"value\": \"2023-08-17T19:19:15.2300718+00:00\"\n}Type: InnerError\nInfo: {\n    \"value\": {\n        \"code\": \"BadArgument\",\n        \"innerError\": {\n            \"code\": \"ArgumentInvalid\",\n            \"innerError\": {\n                \"code\": \"InvalidInputArguments\",\n                \"innerError\": null\n            }\n        }\n    }\n}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ml_client\u001b[39m.\u001b[39;49mbatch_deployments\u001b[39m.\u001b[39;49mbegin_create_or_update(deployment)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     78\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:263\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    261\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, custom_dimensions):\n\u001b[0;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_batch_deployment_operations.py:152\u001b[0m, in \u001b[0;36mBatchDeploymentOperations.begin_create_or_update\u001b[0;34m(self, deployment, skip_script_validation, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_deployment\u001b[39m.\u001b[39mbegin_create_or_update(\n\u001b[1;32m    143\u001b[0m             resource_group_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resource_group_name,\n\u001b[1;32m    144\u001b[0m             workspace_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workspace_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m response, deserialized, headers: BatchDeployment\u001b[39m.\u001b[39m_from_rest_object(deserialized),\n\u001b[1;32m    150\u001b[0m         )\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m--> 152\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_batch_deployment_operations.py:142\u001b[0m, in \u001b[0;36mBatchDeploymentOperations.begin_create_or_update\u001b[0;34m(self, deployment, skip_script_validation, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_component_batch_deployment_operations\u001b[39m.\u001b[39mbegin_create_or_update(\n\u001b[1;32m    131\u001b[0m             resource_group_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resource_group_name,\n\u001b[1;32m    132\u001b[0m             workspace_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workspace_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m             ),\n\u001b[1;32m    140\u001b[0m         )\n\u001b[1;32m    141\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_deployment\u001b[39m.\u001b[39;49mbegin_create_or_update(\n\u001b[1;32m    143\u001b[0m             resource_group_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resource_group_name,\n\u001b[1;32m    144\u001b[0m             workspace_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_workspace_name,\n\u001b[1;32m    145\u001b[0m             endpoint_name\u001b[39m=\u001b[39;49mdeployment\u001b[39m.\u001b[39;49mendpoint_name,\n\u001b[1;32m    146\u001b[0m             deployment_name\u001b[39m=\u001b[39;49mdeployment\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    147\u001b[0m             body\u001b[39m=\u001b[39;49mdeployment_rest,\n\u001b[1;32m    148\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_kwargs,\n\u001b[1;32m    149\u001b[0m             \u001b[39mcls\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m response, deserialized, headers: BatchDeployment\u001b[39m.\u001b[39;49m_from_rest_object(deserialized),\n\u001b[1;32m    150\u001b[0m         )\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m    152\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     78\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_restclient/v2022_05_01/operations/_batch_deployments_operations.py:804\u001b[0m, in \u001b[0;36mBatchDeploymentsOperations.begin_create_or_update\u001b[0;34m(self, resource_group_name, workspace_name, endpoint_name, deployment_name, body, **kwargs)\u001b[0m\n\u001b[1;32m    802\u001b[0m cont_token \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mcontinuation_token\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)  \u001b[39m# type: Optional[str]\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39mif\u001b[39;00m cont_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 804\u001b[0m     raw_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_or_update_initial(\n\u001b[1;32m    805\u001b[0m         resource_group_name\u001b[39m=\u001b[39;49mresource_group_name,\n\u001b[1;32m    806\u001b[0m         workspace_name\u001b[39m=\u001b[39;49mworkspace_name,\n\u001b[1;32m    807\u001b[0m         endpoint_name\u001b[39m=\u001b[39;49mendpoint_name,\n\u001b[1;32m    808\u001b[0m         deployment_name\u001b[39m=\u001b[39;49mdeployment_name,\n\u001b[1;32m    809\u001b[0m         body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    810\u001b[0m         content_type\u001b[39m=\u001b[39;49mcontent_type,\n\u001b[1;32m    811\u001b[0m         \u001b[39mcls\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m x,y,z: x,\n\u001b[1;32m    812\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    813\u001b[0m     )\n\u001b[1;32m    814\u001b[0m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39merror_map\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    816\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_long_running_output\u001b[39m(pipeline_response):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_restclient/v2022_05_01/operations/_batch_deployments_operations.py:736\u001b[0m, in \u001b[0;36mBatchDeploymentsOperations._create_or_update_initial\u001b[0;34m(self, resource_group_name, workspace_name, endpoint_name, deployment_name, body, **kwargs)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m200\u001b[39m, \u001b[39m201\u001b[39m]:\n\u001b[1;32m    735\u001b[0m     map_error(status_code\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mstatus_code, response\u001b[39m=\u001b[39mresponse, error_map\u001b[39m=\u001b[39merror_map)\n\u001b[0;32m--> 736\u001b[0m     \u001b[39mraise\u001b[39;00m HttpResponseError(response\u001b[39m=\u001b[39mresponse, error_format\u001b[39m=\u001b[39mARMErrorFormat)\n\u001b[1;32m    738\u001b[0m response_headers \u001b[39m=\u001b[39m {}\n\u001b[1;32m    739\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n",
            "\u001b[0;31mHttpResponseError\u001b[0m: (UserError) The Deployment request provided has the following validation errors. Please resolve them and try again.\nErrors:\n[\n  {\n    \"PropertyName\": \"ModelConfiguration.EnvironmentId\",\n    \"ErrorMessage\": \"The value specified for 'Environment Id' is not a valid ARM resource identifier.\",\n    \"AttemptedValue\": \"azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\",\n    \"ErrorCode\": \"ArgumentInvalid\"\n  }\n]\n\nCode: UserError\nMessage: The Deployment request provided has the following validation errors. Please resolve them and try again.\nErrors:\n[\n  {\n    \"PropertyName\": \"ModelConfiguration.EnvironmentId\",\n    \"ErrorMessage\": \"The value specified for 'Environment Id' is not a valid ARM resource identifier.\",\n    \"AttemptedValue\": \"azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\",\n    \"ErrorCode\": \"ArgumentInvalid\"\n  }\n]\n\nAdditional Information:Type: ComponentName\nInfo: {\n    \"value\": \"managementfrontend\"\n}Type: Correlation\nInfo: {\n    \"value\": {\n        \"operation\": \"c889250772c5672c6281eccb13f80293\",\n        \"request\": \"5fe34d5f7055c3bd\"\n    }\n}Type: Environment\nInfo: {\n    \"value\": \"australiaeast\"\n}Type: Location\nInfo: {\n    \"value\": \"australiaeast\"\n}Type: Time\nInfo: {\n    \"value\": \"2023-08-17T19:19:15.2300718+00:00\"\n}Type: InnerError\nInfo: {\n    \"value\": {\n        \"code\": \"BadArgument\",\n        \"innerError\": {\n            \"code\": \"ArgumentInvalid\",\n            \"innerError\": {\n                \"code\": \"InvalidInputArguments\",\n                \"innerError\": null\n            }\n        }\n    }\n}"
          ]
        }
      ],
      "source": [
        "ml_client.batch_deployments.begin_create_or_update(deployment)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
