{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Run a training script as a command job\n",
        "\n",
        "You can use the Python SDK for Azure Machine Learning to submit scripts as command jobs. By using jobs, you can easily keep track of the input parameters and outputs when training a machine learning model.\n",
        "\n",
        "## Before you start\n",
        "\n",
        "You'll need the latest version of the **azureml-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
        "\n",
        "> **Note**:\n",
        "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pip show azure-ai-ml"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Name: azure-ai-ml\nVersion: 1.5.0\nSummary: Microsoft Azure Machine Learning Client Library for Python\nHome-page: https://github.com/Azure/azure-sdk-for-python\nAuthor: Microsoft Corporation\nAuthor-email: azuresdkengsysadmins@microsoft.com\nLicense: MIT License\nLocation: /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages\nRequires: azure-common, azure-core, azure-mgmt-core, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, opencensus-ext-azure, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\nRequired-by: \nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1688975492979
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1688975495770
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Custom tracking with MLflow\n",
        "\n",
        "When running a script as a job you can use MLflow in your training script to track the model. MLflow allows you to track any custom parameters, metrics, or artifacts you want to store with your job output.\n",
        "\n",
        "Run the following cells to create the **train-model-mlflow.py** script in the **src** folder. The script trains a classification model by using the **diabetes.csv** file in the same folder, which is passed as an argument. \n",
        "\n",
        "Review the code below to find that the script will import `mlflow` and log:\n",
        "\n",
        "- The regularization rate as a **parameter**. \n",
        "- The accuracy and AUC as **metrics**.\n",
        "- The plotted ROC curve as an **artifact**."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "src folder created\n"
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/train-model-mlflow.py\n",
        "# import libraries\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from mlflow.models import infer_signature\n",
        "\n",
        "\n",
        "\n",
        "from mlflow.pyfunc import PythonModel, PythonModelContext\n",
        "# https://learn.microsoft.com/en-us/azure/machine-learning/how-to-log-mlflow-models?view=azureml-api-2&tabs=wrapper#logging-custom-models\n",
        "class ModelWrapper(PythonModel):\n",
        "    def __init__(self, model):\n",
        "        self._model = model\n",
        "\n",
        "    def predict(self, context: PythonModelContext, data):\n",
        "        # You don't have to keep the semantic meaning of `predict`. You can use here model.recommend(), model.forecast(), etc\n",
        "        return self._model.predict_proba(data)\n",
        "\n",
        "    # You can even add extra functions if you need to. Since the model is serialized,\n",
        "    # all of them will be available when you load your model back.\n",
        "    def predict_batch(self, data):\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test = split_data(df)\n",
        "\n",
        "    # train model\n",
        "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # evaluate model\n",
        "    eval_model(model, X_test, y_test)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    print(\"Reading data...\")\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# function that splits the data\n",
        "def split_data(df):\n",
        "    print(\"Splitting data...\")\n",
        "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
        "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# function that trains the model\n",
        "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
        "    mlflow.log_param(\"Regularization rate\", reg_rate)\n",
        "    print(\"Training model...\")\n",
        "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    y_probs = model.predict_proba(X_test)\n",
        "\n",
        "    #Logging the model artifact\n",
        "    signature = infer_signature(X_test, y_probs)\n",
        "    mlflow.pyfunc.log_model(\"classifier\", \n",
        "                        python_model=ModelWrapper(model),\n",
        "                        signature=signature)\n",
        "    \n",
        "\n",
        "    return model\n",
        "\n",
        "# function that evaluates the model\n",
        "def eval_model(model, X_test, y_test):\n",
        "    # calculate accuracy\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        "    mlflow.log_metric(\"Accuracy\", acc)\n",
        "\n",
        "    # calculate AUC\n",
        "    y_scores = model.predict_proba(X_test)\n",
        "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "    print('AUC: ' + str(auc))\n",
        "    mlflow.log_metric(\"AUC\", auc)\n",
        "\n",
        "    # plot ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    # Plot the diagonal 50% line\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    # Plot the FPR and TPR achieved by our model\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.savefig(\"ROC-Curve.png\")\n",
        "    mlflow.log_artifact(\"ROC-Curve.png\")    \n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
        "                        type=float, default=0.01)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting src/train-model-mlflow.py\n"
        }
      ],
      "execution_count": 30,
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Now, you can submit the script as a command job.\n",
        "\n",
        "Run the cell below to train the model. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command\n",
        "\n",
        "# configure job\n",
        "\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python train-model-mlflow.py --training_data diabetes.csv\",\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"farbodtaymouri1\",\n",
        "    display_name=\"diabetes-train-mlflow\",\n",
        "    experiment_name=\"diabetes-training2\", \n",
        "    tags={\"model_type\": \"LogisticRegression\"}\n",
        "    )\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Monitor your job at https://ml.azure.com/runs/plucky_jicama_t7yjfgd94h?wsid=/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourcegroups/mlcertificate/workspaces/ft_ml&tid=71f8feea-4caa-4230-a785-dca61147bceb\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1688975506861
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "In the Studio, navigate to the **diabetes-train-mlflow** job to explore the overview of the command job you ran:\n",
        "\n",
        "- Find the logged parameters in the **Overview** tab, under **Params**.\n",
        "- Find the logged metrics in the **Metrics** tab.\n",
        "- Find the logged artifacts in the **Images** tab (specifically for images), and in the **Outputs + logs** tab (all files)."
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Autologging with MLflow\n",
        "\n",
        "Instead of using custom logging, MLflow can also automatically log any parameters, metrics, and artifacts. Autologging with MLflow requires only one line of code.\n",
        "\n",
        "Run the following cell to create the **train-model-autolog.py** script in the **src** folder. The script trains a classification model by using the **diabetes.csv** file in the same folder, which is passed as an argument. \n",
        "\n",
        "Review the code below to find that the script will import `mlflow` and enables autologging with the line: \n",
        "\n",
        "`mlflow.autolog()`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/train-model-autolog.py\n",
        "# import libraries\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def main(args):\n",
        "    # enable autologging\n",
        "    mlflow.autolog()\n",
        "\n",
        "    # read data\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test = split_data(df)\n",
        "\n",
        "    # train model\n",
        "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    eval_model(model, X_test, y_test)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    print(\"Reading data...\")\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# function that splits the data\n",
        "def split_data(df):\n",
        "    print(\"Splitting data...\")\n",
        "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
        "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# function that trains the model\n",
        "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
        "    mlflow.log_param(\"Regularization rate\", reg_rate)\n",
        "    print(\"Training model...\")\n",
        "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "    \n",
        "\n",
        "    return model\n",
        "\n",
        "# function that evaluates the model\n",
        "def eval_model(model, X_test, y_test):\n",
        "    # calculate accuracy\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        "\n",
        "    # calculate AUC\n",
        "    y_scores = model.predict_proba(X_test)\n",
        "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "    print('AUC: ' + str(auc))\n",
        "\n",
        "    # plot ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    # Plot the diagonal 50% line\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    # Plot the FPR and TPR achieved by our model\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.savefig(\"ROC-Curve.png\") \n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
        "                        type=float, default=0.01)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting src/train-model-autolog.py\n"
        }
      ],
      "execution_count": 21,
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Now, you can submit the script as a command job.\n",
        "\n",
        "Run the cell below to train the model. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command\n",
        "\n",
        "# configure job\n",
        "\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python train-model-autolog.py --training_data diabetes.csv\",\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"farbodtaymouri1\",\n",
        "    display_name=\"diabetes-train-autolog\",\n",
        "    experiment_name=\"diabetes-training\"\n",
        "    )\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[32mUploading src (0.57 MBs): 100%|██████████| 571727/571727 [00:00<00:00, 6633316.12it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Monitor your job at https://ml.azure.com/runs/modest_nerve_lsgg9mrjwl?wsid=/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourcegroups/mlcertificate/workspaces/ft_ml&tid=71f8feea-4caa-4230-a785-dca61147bceb\n"
        }
      ],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# https://ftml2793558306.blob.core.windows.net/azureml/ExperimentRun/dcid.icy_oyster_b0xwtdqfs8/ROC-Curve.png\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/farbodtaymouri1/code/Users/farbodtaymouri/azure-ml-labs/Labs/08'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "In the Studio, navigate to the **diabetes-train-autolog** job to explore the overview of the command job you ran:\n",
        "\n",
        "- Find the logged parameters in the **Overview** tab, under **Params**.\n",
        "- Find the logged metrics in the **Metrics** tab.\n",
        "- Find the logged artifacts in the **Images** tab (specifically for images), and in the **Outputs + logs** tab (all files, including the model files)."
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Use MLflow to view and search for experiments\n",
        "\n",
        "The Azure Machine Learning Studio is an easy-to-use UI to view and compare job runs. Alternatively, you can use MLflow to view experiment jobs. \n",
        "\n",
        "To list the jobs in the workspace, use the following command to list the experiments in the workspace:\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "experiments = mlflow.search_experiments()\n",
        "for exp in experiments:\n",
        "    print(exp.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipe_test1\ndiabetes-training\n"
        }
      ],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "To retrieve a specific experiment, you can get it by its name:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_name = \"diabetes-training\"\n",
        "exp = mlflow.get_experiment_by_name(experiment_name)\n",
        "print(exp)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<Experiment: artifact_location='', creation_time=1686709541661, experiment_id='75b44b6b-74a0-4eb3-bbeb-3bb14a56c5dc', last_update_time=None, lifecycle_stage='active', name='diabetes-training', tags={}>\n"
        }
      ],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Using an experiment name, you can retrieve all jobs of that experiment:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.search_runs(exp.experiment_id)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run_id</th>\n      <th>experiment_id</th>\n      <th>status</th>\n      <th>artifact_uri</th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>metrics.Accuracy</th>\n      <th>metrics.AUC</th>\n      <th>metrics.training_recall_score</th>\n      <th>metrics.training_score</th>\n      <th>...</th>\n      <th>params.warm_start</th>\n      <th>params.multi_class</th>\n      <th>params.random_state</th>\n      <th>params.max_iter</th>\n      <th>tags.mlflow.user</th>\n      <th>tags.mlflow.runName</th>\n      <th>tags.mlflow.rootRunId</th>\n      <th>tags.model_type</th>\n      <th>tags.estimator_class</th>\n      <th>tags.estimator_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ashy_avocado_ft7ych7s64</td>\n      <td>75b44b6b-74a0-4eb3-bbeb-3bb14a56c5dc</td>\n      <td>FINISHED</td>\n      <td></td>\n      <td>2023-06-14 02:25:57.389000+00:00</td>\n      <td>2023-06-14 02:27:07.363000+00:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>farbod Taymouri</td>\n      <td>diabetes-pythonv2-train</td>\n      <td>ashy_avocado_ft7ych7s64</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>icy_curtain_ry18w1q3l5</td>\n      <td>75b44b6b-74a0-4eb3-bbeb-3bb14a56c5dc</td>\n      <td>FINISHED</td>\n      <td></td>\n      <td>2023-06-19 05:33:43.294000+00:00</td>\n      <td>2023-06-19 05:35:03.773000+00:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>farbod Taymouri</td>\n      <td>diabetes-train-script</td>\n      <td>icy_curtain_ry18w1q3l5</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>patient_key_h2z69yhn0d</td>\n      <td>75b44b6b-74a0-4eb3-bbeb-3bb14a56c5dc</td>\n      <td>FINISHED</td>\n      <td></td>\n      <td>2023-06-19 07:05:09.276000+00:00</td>\n      <td>2023-06-19 07:05:23.063000+00:00</td>\n      <td>0.774</td>\n      <td>0.848321</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>farbod Taymouri</td>\n      <td>diabetes-train-mlflow</td>\n      <td>patient_key_h2z69yhn0d</td>\n      <td>LogisticRegression</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>modest_nerve_lsgg9mrjwl</td>\n      <td>75b44b6b-74a0-4eb3-bbeb-3bb14a56c5dc</td>\n      <td>FINISHED</td>\n      <td></td>\n      <td>2023-06-19 07:07:33.837000+00:00</td>\n      <td>2023-06-19 07:07:50.691000+00:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.790857</td>\n      <td>0.790857</td>\n      <td>...</td>\n      <td>False</td>\n      <td>auto</td>\n      <td>None</td>\n      <td>100</td>\n      <td>farbod Taymouri</td>\n      <td>diabetes-train-autolog</td>\n      <td>modest_nerve_lsgg9mrjwl</td>\n      <td>None</td>\n      <td>sklearn.linear_model._logistic.LogisticRegression</td>\n      <td>LogisticRegression</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 37 columns</p>\n</div>",
            "text/plain": "                    run_id                         experiment_id    status   \n0  ashy_avocado_ft7ych7s64  75b44b6b-74a0-4eb3-bbeb-3bb14a56c5dc  FINISHED  \\\n1   icy_curtain_ry18w1q3l5  75b44b6b-74a0-4eb3-bbeb-3bb14a56c5dc  FINISHED   \n2   patient_key_h2z69yhn0d  75b44b6b-74a0-4eb3-bbeb-3bb14a56c5dc  FINISHED   \n3  modest_nerve_lsgg9mrjwl  75b44b6b-74a0-4eb3-bbeb-3bb14a56c5dc  FINISHED   \n\n  artifact_uri                       start_time   \n0              2023-06-14 02:25:57.389000+00:00  \\\n1              2023-06-19 05:33:43.294000+00:00   \n2              2023-06-19 07:05:09.276000+00:00   \n3              2023-06-19 07:07:33.837000+00:00   \n\n                          end_time  metrics.Accuracy  metrics.AUC   \n0 2023-06-14 02:27:07.363000+00:00               NaN          NaN  \\\n1 2023-06-19 05:35:03.773000+00:00               NaN          NaN   \n2 2023-06-19 07:05:23.063000+00:00             0.774     0.848321   \n3 2023-06-19 07:07:50.691000+00:00               NaN          NaN   \n\n   metrics.training_recall_score  metrics.training_score  ...   \n0                            NaN                     NaN  ...  \\\n1                            NaN                     NaN  ...   \n2                            NaN                     NaN  ...   \n3                       0.790857                0.790857  ...   \n\n   params.warm_start  params.multi_class  params.random_state   \n0               None                None                 None  \\\n1               None                None                 None   \n2               None                None                 None   \n3              False                auto                 None   \n\n   params.max_iter  tags.mlflow.user      tags.mlflow.runName   \n0             None   farbod Taymouri  diabetes-pythonv2-train  \\\n1             None   farbod Taymouri    diabetes-train-script   \n2             None   farbod Taymouri    diabetes-train-mlflow   \n3              100   farbod Taymouri   diabetes-train-autolog   \n\n     tags.mlflow.rootRunId     tags.model_type   \n0  ashy_avocado_ft7ych7s64                None  \\\n1   icy_curtain_ry18w1q3l5                None   \n2   patient_key_h2z69yhn0d  LogisticRegression   \n3  modest_nerve_lsgg9mrjwl                None   \n\n                                tags.estimator_class tags.estimator_name  \n0                                               None                None  \n1                                               None                None  \n2                                               None                None  \n3  sklearn.linear_model._logistic.LogisticRegression  LogisticRegression  \n\n[4 rows x 37 columns]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "To more easily compare job runs and outputs, you can configure the search to order the results. For example, the following cell orders the results by `start_time`, and only shows a maximum of `2` results: "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.search_runs(exp.experiment_id, order_by=[\"start_time DESC\"], max_results=2)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run_id</th>\n      <th>experiment_id</th>\n      <th>status</th>\n      <th>artifact_uri</th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>metrics.training_precision_score</th>\n      <th>metrics.training_recall_score</th>\n      <th>metrics.training_score</th>\n      <th>metrics.training_accuracy_score</th>\n      <th>...</th>\n      <th>params.warm_start</th>\n      <th>params.multi_class</th>\n      <th>params.random_state</th>\n      <th>params.max_iter</th>\n      <th>tags.mlflow.user</th>\n      <th>tags.mlflow.rootRunId</th>\n      <th>tags.estimator_class</th>\n      <th>tags.estimator_name</th>\n      <th>tags.mlflow.runName</th>\n      <th>tags.model_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>modest_nerve_lsgg9mrjwl</td>\n      <td>75b44b6b-74a0-4eb3-bbeb-3bb14a56c5dc</td>\n      <td>FINISHED</td>\n      <td></td>\n      <td>2023-06-19 07:07:33.837000+00:00</td>\n      <td>2023-06-19 07:07:50.691000+00:00</td>\n      <td>0.78576</td>\n      <td>0.790857</td>\n      <td>0.790857</td>\n      <td>0.790857</td>\n      <td>...</td>\n      <td>False</td>\n      <td>auto</td>\n      <td>None</td>\n      <td>100</td>\n      <td>farbod Taymouri</td>\n      <td>modest_nerve_lsgg9mrjwl</td>\n      <td>sklearn.linear_model._logistic.LogisticRegression</td>\n      <td>LogisticRegression</td>\n      <td>diabetes-train-autolog</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>patient_key_h2z69yhn0d</td>\n      <td>75b44b6b-74a0-4eb3-bbeb-3bb14a56c5dc</td>\n      <td>FINISHED</td>\n      <td></td>\n      <td>2023-06-19 07:05:09.276000+00:00</td>\n      <td>2023-06-19 07:05:23.063000+00:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>farbod Taymouri</td>\n      <td>patient_key_h2z69yhn0d</td>\n      <td>None</td>\n      <td>None</td>\n      <td>diabetes-train-mlflow</td>\n      <td>LogisticRegression</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 37 columns</p>\n</div>",
            "text/plain": "                    run_id                         experiment_id    status   \n0  modest_nerve_lsgg9mrjwl  75b44b6b-74a0-4eb3-bbeb-3bb14a56c5dc  FINISHED  \\\n1   patient_key_h2z69yhn0d  75b44b6b-74a0-4eb3-bbeb-3bb14a56c5dc  FINISHED   \n\n  artifact_uri                       start_time   \n0              2023-06-19 07:07:33.837000+00:00  \\\n1              2023-06-19 07:05:09.276000+00:00   \n\n                          end_time  metrics.training_precision_score   \n0 2023-06-19 07:07:50.691000+00:00                           0.78576  \\\n1 2023-06-19 07:05:23.063000+00:00                               NaN   \n\n   metrics.training_recall_score  metrics.training_score   \n0                       0.790857                0.790857  \\\n1                            NaN                     NaN   \n\n   metrics.training_accuracy_score  ...  params.warm_start   \n0                         0.790857  ...              False  \\\n1                              NaN  ...               None   \n\n   params.multi_class  params.random_state  params.max_iter  tags.mlflow.user   \n0                auto                 None              100   farbod Taymouri  \\\n1                None                 None             None   farbod Taymouri   \n\n     tags.mlflow.rootRunId                               tags.estimator_class   \n0  modest_nerve_lsgg9mrjwl  sklearn.linear_model._logistic.LogisticRegression  \\\n1   patient_key_h2z69yhn0d                                               None   \n\n  tags.estimator_name     tags.mlflow.runName     tags.model_type  \n0  LogisticRegression  diabetes-train-autolog                None  \n1                None   diabetes-train-mlflow  LogisticRegression  \n\n[2 rows x 37 columns]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "You can even create a query to filter the runs. Filter query strings are written with a simplified version of the SQL `WHERE` clause. \n",
        "\n",
        "To filter, you can use two classes of comparators:\n",
        "\n",
        "- Numeric comparators (metrics): =, !=, >, >=, <, and <=.\n",
        "- String comparators (params, tags, and attributes): = and !=.\n",
        "\n",
        "Learn more about [how to track experiments with MLflow](https://learn.microsoft.com/azure/machine-learning/how-to-track-experiments-mlflow)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"metrics.AUC > 0.8 and tags.model_type = 'LogisticRegression'\"\n",
        "mlflow.search_runs(exp.experiment_id, filter_string=query)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run_id</th>\n      <th>experiment_id</th>\n      <th>status</th>\n      <th>artifact_uri</th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>metrics.Accuracy</th>\n      <th>metrics.AUC</th>\n      <th>params.Regularization rate</th>\n      <th>tags.mlflow.user</th>\n      <th>tags.mlflow.runName</th>\n      <th>tags.model_type</th>\n      <th>tags.mlflow.rootRunId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>patient_key_h2z69yhn0d</td>\n      <td>75b44b6b-74a0-4eb3-bbeb-3bb14a56c5dc</td>\n      <td>FINISHED</td>\n      <td></td>\n      <td>2023-06-19 07:05:09.276000+00:00</td>\n      <td>2023-06-19 07:05:23.063000+00:00</td>\n      <td>0.774</td>\n      <td>0.848321</td>\n      <td>0.01</td>\n      <td>farbod Taymouri</td>\n      <td>diabetes-train-mlflow</td>\n      <td>LogisticRegression</td>\n      <td>patient_key_h2z69yhn0d</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                   run_id                         experiment_id    status   \n0  patient_key_h2z69yhn0d  75b44b6b-74a0-4eb3-bbeb-3bb14a56c5dc  FINISHED  \\\n\n  artifact_uri                       start_time   \n0              2023-06-19 07:05:09.276000+00:00  \\\n\n                          end_time  metrics.Accuracy  metrics.AUC   \n0 2023-06-19 07:05:23.063000+00:00             0.774     0.848321  \\\n\n  params.Regularization rate tags.mlflow.user    tags.mlflow.runName   \n0                       0.01  farbod Taymouri  diabetes-train-mlflow  \\\n\n      tags.model_type   tags.mlflow.rootRunId  \n0  LogisticRegression  patient_key_h2z69yhn0d  "
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}