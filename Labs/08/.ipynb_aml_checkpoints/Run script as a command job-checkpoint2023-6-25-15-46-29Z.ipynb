{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run a training script as a command job\n",
        "\n",
        "You can use the Python SDK for Azure Machine Learning to submit scripts as command jobs. By using jobs, you can easily keep track of the input parameters and outputs when training a machine learning model.\n",
        "\n",
        "## Before you start\n",
        "\n",
        "You'll need the latest version of the  **azureml-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
        "\n",
        "> **Note**:\n",
        "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: azure-ai-ml\n",
            "Version: 1.5.0\n",
            "Summary: Microsoft Azure Machine Learning Client Library for Python\n",
            "Home-page: https://github.com/Azure/azure-sdk-for-python\n",
            "Author: Microsoft Corporation\n",
            "Author-email: azuresdkengsysadmins@microsoft.com\n",
            "License: MIT License\n",
            "Location: /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages\n",
            "Requires: azure-common, azure-core, azure-mgmt-core, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, opencensus-ext-azure, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\n",
            "Required-by: \n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip show azure-ai-ml"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1663753569264
        }
      },
      "outputs": [],
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: /config.json\n"
          ]
        }
      ],
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initiate a command job\n",
        "\n",
        "Run the cell below to train a classification model to predict diabetes. The model is trained by running the **train-model-parameters.py** script that can be found in the **src** folder. It uses the **diabetes.csv** file as the training data. \n",
        "\n",
        "- `code`: specifies the folder that includes the script to run.\n",
        "- `command`: specifies what to run exactly.\n",
        "- `environment`: specifies the necessary packages to be installed on the compute before running the command.\n",
        "- `compute`: specifies the compute to use to run the command.\n",
        "- `display_name`: the name of the individual job.\n",
        "- `experiment_name`: the name of the experiment the job belongs to.\n",
        "\n",
        "Note that the command used to test the script in the terminal is the same as the command in the configuration of the job below. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mUploading src (0.57 MBs): 100%|██████████| 571617/571617 [00:00<00:00, 10646344.41it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Monitor your job at https://ml.azure.com/runs/joyful_gyro_82nlvfvxz8?wsid=/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourcegroups/mlcertificate/workspaces/ft_ml&tid=71f8feea-4caa-4230-a785-dca61147bceb\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml import command\n",
        "\n",
        "# # configure job\n",
        "\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python train-model-parameters.py --training_data diabetes.csv\",\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"farbodtaymouri1\",\n",
        "    display_name=\"diabetes-train-script\",\n",
        "    experiment_name=\"diabetes-training\"\n",
        "    )\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function command in module azure.ai.ml.entities._builders.command_func:\n",
            "\n",
            "command(*, name: Optional[str] = None, description: Optional[str] = None, tags: Optional[Dict] = None, properties: Optional[Dict] = None, display_name: Optional[str] = None, command: Optional[str] = None, experiment_name: Optional[str] = None, environment: Union[str, azure.ai.ml.entities._assets.environment.Environment, NoneType] = None, environment_variables: Optional[Dict] = None, distribution: Union[Dict, azure.ai.ml.entities._job.distribution.MpiDistribution, azure.ai.ml.entities._job.distribution.TensorFlowDistribution, azure.ai.ml.entities._job.distribution.PyTorchDistribution, NoneType] = None, compute: Optional[str] = None, inputs: Optional[Dict] = None, outputs: Optional[Dict] = None, instance_count: Optional[int] = None, instance_type: Optional[str] = None, locations: Optional[List[str]] = None, docker_args: Optional[str] = None, shm_size: Optional[str] = None, timeout: Optional[int] = None, code: Union[os.PathLike, str, NoneType] = None, identity: Union[azure.ai.ml.entities._credentials.ManagedIdentityConfiguration, azure.ai.ml.entities._credentials.AmlTokenConfiguration, azure.ai.ml.entities._credentials.UserIdentityConfiguration, NoneType] = None, is_deterministic: bool = True, services: Optional[Dict[str, Union[azure.ai.ml.entities._job.job_service.JobService, azure.ai.ml.entities._job.job_service.JupyterLabJobService, azure.ai.ml.entities._job.job_service.SshJobService, azure.ai.ml.entities._job.job_service.TensorBoardJobService, azure.ai.ml.entities._job.job_service.VsCodeJobService]]] = None, job_tier: Optional[str] = None, priority: Optional[str] = None, **kwargs) -> azure.ai.ml.entities._builders.command.Command\n",
            "    Create a Command object which can be used inside dsl.pipeline as a function and can also be created as a\n",
            "    standalone command job.\n",
            "    \n",
            "    :param name: Name of the command job or component created\n",
            "    :type name: str\n",
            "    :param description: a friendly description of the command\n",
            "    :type description: str\n",
            "    :param tags: Tags to be attached to this command\n",
            "    :type tags: Dict\n",
            "    :param properties: The asset property dictionary.\n",
            "    :type properties: dict[str, str]\n",
            "    :param display_name: a friendly name\n",
            "    :type display_name: str\n",
            "    :param experiment_name:  Name of the experiment the job will be created under,\n",
            "        if None is provided, default will be set to current directory name. Will be ignored as a pipeline step.\n",
            "    :type experiment_name: str\n",
            "    :param command: the command string that will be run\n",
            "    :type command: str\n",
            "    :param environment: the environment to use for this command\n",
            "    :type environment: Union[str, azure.ai.ml.entities.Environment]\n",
            "    :param environment_variables: environment variables to set on the compute before this command is executed\n",
            "    :type environment_variables: dict\n",
            "    :param distribution: the distribution mode to use for this command\n",
            "    :type distribution:\n",
            "        Union[Dict, azure.ai.ml.MpiDistribution, azure.ai.ml.TensorFlowDistribution, azure.ai.ml.PyTorchDistribution]\n",
            "    :param compute: the name of the compute where the command job is executed(\n",
            "        will not be used if the command is used as a component/function)\n",
            "    :type compute: str\n",
            "    :param inputs: a dict of inputs used by this command.\n",
            "    :type inputs: Dict\n",
            "    :param outputs: the outputs of this command\n",
            "    :type outputs: Dict\n",
            "    :param instance_count: Optional number of instances or nodes used by the compute target. Defaults to 1.\n",
            "    :vartype instance_count: int\n",
            "    :param instance_type: Optional type of VM used as supported by the compute target.\n",
            "    :vartype instance_type: str\n",
            "    :param locations: Optional list of locations where the job can run.\n",
            "    :vartype locations: List[str]\n",
            "    :param docker_args: Extra arguments to pass to the Docker run command. This would override any\n",
            "     parameters that have already been set by the system, or in this section. This parameter is only\n",
            "     supported for Azure ML compute types.\n",
            "    :vartype docker_args: str\n",
            "    :param shm_size: Size of the docker container's shared memory block. This should be in the\n",
            "     format of (number)(unit) where number as to be greater than 0 and the unit can be one of\n",
            "     b(bytes), k(kilobytes), m(megabytes), or g(gigabytes).\n",
            "    :vartype shm_size: str\n",
            "    :param timeout: The number in seconds, after which the job will be cancelled.\n",
            "    :vartype timeout: int\n",
            "    :param code: the code folder to run -- typically a local folder that will be uploaded as the job is submitted\n",
            "    :type code: Union[str, os.PathLike]\n",
            "    :param identity: Identity that training job will use while running on compute.\n",
            "    :type identity: Union[\n",
            "        azure.ai.ml.ManagedIdentityConfiguration,\n",
            "        azure.ai.ml.AmlTokenConfiguration]\n",
            "    :param is_deterministic: Specify whether the command will return same output given same input.\n",
            "        If a command (component) is deterministic, when use it as a node/step in a pipeline,\n",
            "        it will reuse results from a previous submitted job in current workspace which has same inputs and settings.\n",
            "        In this case, this step will not use any compute resource.\n",
            "        Default to be True, specify is_deterministic=False if you would like to avoid such reuse behavior.\n",
            "    :type is_deterministic: bool\n",
            "    :param services: Interactive services for the node. This is an experimental parameter, and may change at any time.\n",
            "        Please see https://aka.ms/azuremlexperimental for more information.\n",
            "    :type services: Dict[str, JobService]\n",
            "    :param job_tier: **Experimental** determines the job tier.\n",
            "    :type job_tier: str\n",
            "    :param priority: **Experimental** controls the priority on the compute.\n",
            "    :type priority: str\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(command)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
