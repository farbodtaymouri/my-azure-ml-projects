{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Deploy to an online endpoint\n",
        "\n",
        "To consume a model from an application, you can deploy the model to an online endpoint. You'll create an MLflow model from local files and test the endpoint.\n",
        "\n",
        "## Before you start\n",
        "\n",
        "You'll need the latest version of the  **azureml-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
        "\n",
        "> **Note**:\n",
        "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pip show azure-ai-ml"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Name: azure-ai-ml\r\nVersion: 1.8.0\r\nSummary: Microsoft Azure Machine Learning Client Library for Python\r\nHome-page: https://github.com/Azure/azure-sdk-for-python\r\nAuthor: Microsoft Corporation\r\nAuthor-email: azuresdkengsysadmins@microsoft.com\r\nLicense: MIT License\r\nLocation: /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages\r\nRequires: azure-common, azure-core, azure-mgmt-core, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, opencensus-ext-azure, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\r\nRequired-by: \r\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1690285406272
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1690293577400
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1690293579403
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Define and create an endpoint\n",
        "\n",
        "Ultimately, the goal is to deploy a model to an endpoint. Therefore, you first need to create an endpoint. The endpoint will be a HTTPS endpoint that an application can call to receive predictions from the model. An application can consume an endpoint by using its URI, and authenticating with a key or token.\n",
        "\n",
        "Run the following cell to define the endpoint. Note that the name of the endpoint has to be unique. You'll use the `datetime` function to generate a unique name."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
        "import datetime\n",
        "\n",
        "online_endpoint_name = \"endpoint-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=\"Online endpoint for MLflow diabetes model\",\n",
        "    auth_mode=\"key\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1690293676182
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "online_endpoint_name\n",
        "endpoint"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "ManagedOnlineEndpoint({'public_network_access': None, 'provisioning_state': None, 'scoring_uri': None, 'openapi_uri': None, 'name': 'endpoint-07251401032082', 'description': 'Online endpoint for MLflow diabetes model', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/farbodtaymouri2/code/my-azure-ml-projects/Labs/11', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f5bed490220>, 'auth_mode': 'key', 'location': None, 'identity': None, 'traffic': {}, 'mirror_traffic': {}, 'kind': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1690293687051
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(ManagedOnlineEndpoint)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Next, you'll create the endpoint by running the following cell. This may take several minutes. While your endpoint is being created, you can read about [what are Azure Machine Learning endpoints](https://learn.microsoft.com/azure/machine-learning/concept-endpoints)."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.begin_create_or_update(endpoint).result()\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://endpoint-07251401032082.australiaeast.inference.ml.azure.com/score', 'openapi_uri': 'https://endpoint-07251401032082.australiaeast.inference.ml.azure.com/swagger.json', 'name': 'endpoint-07251401032082', 'description': 'Online endpoint for MLflow diabetes model', 'tags': {}, 'properties': {'azureml.onlineendpointid': '/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourcegroups/mlcertificate1/providers/microsoft.machinelearningservices/workspaces/ft_ml2/onlineendpoints/endpoint-07251401032082', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/providers/Microsoft.MachineLearningServices/locations/australiaeast/mfeOperationsStatus/oe:44ba2fae-86c8-4414-b8fd-2b7466f5958e:0e7857d0-4fa9-4d6f-8c3d-faf0fdd23d84?api-version=2022-02-01-preview'}, 'print_as_yaml': True, 'id': '/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourceGroups/mlcertificate1/providers/Microsoft.MachineLearningServices/workspaces/ft_ml2/onlineEndpoints/endpoint-07251401032082', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/farbodtaymouri2/code/my-azure-ml-projects/Labs/11', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f5bed64f970>, 'auth_mode': 'key', 'location': 'australiaeast', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7f5bed64aec0>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1690293785390
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eps = ml_client.online_endpoints.list()\n",
        "for ep in eps:\n",
        "    print(ep.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "endpoint-07251401032082\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1690293813989
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANT! Wait until the endpoint is created successfully before continuing! A green notification should appear in the studio. </p>\n",
        "\n",
        "## Configure the deployment\n",
        "\n",
        "You can deploy multiple models to an endpoint. This is mostly useful when you want to update the deployed model while keeping the current model in production. You'll need to configure the deployment to specify which model needs to be deployed to an endpoint. In the following cell, you'll refer to the model trained and stored in the local `model` folder (stored in the same folder as this notebook). Note that since you're working with an MLflow model, you don't need to specify the environment or scoring script.\n",
        "\n",
        "You'll also specify the infrastructure needed for the model to be deployed."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Model, ManagedOnlineDeployment\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# create a blue deployment\n",
        "model = Model(\n",
        "    path=\"./model\",\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        "    description=\"my sample mlflow model\",\n",
        ")\n",
        "\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=model,\n",
        "    instance_type=\"STANDARD_E2S_V3\",\n",
        "    instance_count=1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1690296117138
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create the deployment\n",
        "\n",
        "Finally, you can actually deploy the model to the endpoint by running the following cell:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_deployments.begin_create_or_update(blue_deployment).result()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint endpoint-07251401032082 exists\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "......................................"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1690295108106
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "The deployment of the model may take 10-15 minutes. While waiting for the model to be deployed, you can learn more about [managed endpoints in this video](https://www.youtube.com/watch?v=SxFGw_OBxNM&ab_channel=MicrosoftDeveloper).\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANT! Wait until the deployment is completed before continuing! A green notification should appear in the studio.</p>\n",
        "\n",
        "Since you only have one model deployed to the endpoint, you want this deployment to take 100% of the traffic. If you deploy multiple models to the endpoint, you could use the same approach to distribute traffic across the deployed models."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# blue deployment takes 100 traffic\n",
        "endpoint.traffic = {\"blue\": 100}\n",
        "ml_client.begin_create_or_update(endpoint).result()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667341237843
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANT! Wait until the blue deployment is configured before continuing! A green notification should appear in the studio. </p> \n",
        "\n",
        "## Test the deployment\n",
        "\n",
        "Let's test the deployed model by invoking the endpoint. A JSON file with sample data is used as input. The trained model predicts whether a patient has diabetes or not, based on medical data like age, BMI, and the number of pregnancies. A `[0]` indicates a patient doesn't have diabetes. A `[1]` means a patient does have diabetes."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test the blue deployment with some sample data\n",
        "response = ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    deployment_name=\"blue\",\n",
        "    request_file=\"sample-data.json\",\n",
        ")\n",
        "\n",
        "if response[1]=='1':\n",
        "    print(\"Diabetic\")\n",
        "else:\n",
        "    print (\"Not diabetic\")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ServiceResponseError",
          "evalue": "('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mServiceResponseError\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[62], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# test the blue deployment with some sample data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m response \u001b[39m=\u001b[39m ml_client\u001b[39m.\u001b[39;49monline_endpoints\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m      3\u001b[0m     endpoint_name\u001b[39m=\u001b[39;49monline_endpoint_name,\n\u001b[1;32m      4\u001b[0m     deployment_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mblue\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     request_file\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msample-data.json\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m response[\u001b[39m1\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39m1\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m      9\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDiabetic\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     78\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:263\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    261\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, custom_dimensions):\n\u001b[0;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_online_endpoint_operations.py:356\u001b[0m, in \u001b[0;36mOnlineEndpointOperations.invoke\u001b[0;34m(self, endpoint_name, request_file, deployment_name, input_data, params_override, local, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[39mif\u001b[39;00m deployment_name:\n\u001b[1;32m    354\u001b[0m     headers[EndpointInvokeFields\u001b[39m.\u001b[39mMODEL_DEPLOYMENT] \u001b[39m=\u001b[39m deployment_name\n\u001b[0;32m--> 356\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_requests_pipeline\u001b[39m.\u001b[39;49mpost(endpoint\u001b[39m.\u001b[39;49mproperties\u001b[39m.\u001b[39;49mscoring_uri, json\u001b[39m=\u001b[39;49mdata, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m    357\u001b[0m validate_response(response)\n\u001b[1;32m    358\u001b[0m \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mtext()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_utils/_http_utils.py:63\u001b[0m, in \u001b[0;36m_request_function.<locals>._.<locals>.decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39m\"\"\"A function that sends an HTTP request and returns the response.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[39mAccepts the same parameters as azure.core.rest.HttpRequest, except for the method.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m:return HttpResponse:\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m request \u001b[39m=\u001b[39m HttpRequest(\n\u001b[1;32m     53\u001b[0m     f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m.\u001b[39mupper(),\n\u001b[1;32m     54\u001b[0m     \u001b[39m*\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     files\u001b[39m=\u001b[39mkwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mfiles\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m     61\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mhttp_response\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/_base.py:202\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m pipeline_request: PipelineRequest[HTTPRequestType] \u001b[39m=\u001b[39m PipelineRequest(request, context)\n\u001b[1;32m    201\u001b[0m first_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl_policies[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl_policies \u001b[39melse\u001b[39;00m _TransportRunner(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport)\n\u001b[0;32m--> 202\u001b[0m \u001b[39mreturn\u001b[39;00m first_node\u001b[39m.\u001b[39;49msend(pipeline_request)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/_base.py:70\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     68\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[1;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/_base.py:70\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     68\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[1;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/_base.py:70\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     68\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[1;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/policies/_redirect.py:156\u001b[0m, in \u001b[0;36mRedirectPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    154\u001b[0m redirect_settings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfigure_redirects(request\u001b[39m.\u001b[39mcontext\u001b[39m.\u001b[39moptions)\n\u001b[1;32m    155\u001b[0m \u001b[39mwhile\u001b[39;00m retryable:\n\u001b[0;32m--> 156\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m    157\u001b[0m     redirect_location \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_redirect_location(response)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m redirect_location \u001b[39mand\u001b[39;00m redirect_settings[\u001b[39m\"\u001b[39m\u001b[39mallow\u001b[39m\u001b[39m\"\u001b[39m]:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/policies/_retry.py:470\u001b[0m, in \u001b[0;36mRetryPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    468\u001b[0m                 is_response_error \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    469\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 470\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m    471\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    472\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/policies/_retry.py:448\u001b[0m, in \u001b[0;36mRetryPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    446\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_timeout(request, absolute_timeout, is_response_error)\n\u001b[0;32m--> 448\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_retry(retry_settings, response):\n\u001b[1;32m    450\u001b[0m     retry_active \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mincrement(retry_settings, response\u001b[39m=\u001b[39mresponse)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/_base.py:70\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     68\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[1;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/_base.py:70\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     68\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[1;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/_base.py:101\u001b[0m, in \u001b[0;36m_TransportRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend\u001b[39m(\u001b[39mself\u001b[39m, request: PipelineRequest[HTTPRequestType]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PipelineResponse[HTTPRequestType, HTTPResponseType]:\n\u001b[1;32m     92\u001b[0m     \u001b[39m\"\"\"HTTP transport send method.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \n\u001b[1;32m     94\u001b[0m \u001b[39m    :param request: The PipelineRequest object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39m    :rtype: ~azure.core.pipeline.PipelineResponse\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39mreturn\u001b[39;00m PipelineResponse(\n\u001b[1;32m    100\u001b[0m         request\u001b[39m.\u001b[39mhttp_request,\n\u001b[0;32m--> 101\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sender\u001b[39m.\u001b[39;49msend(request\u001b[39m.\u001b[39;49mhttp_request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrequest\u001b[39m.\u001b[39;49mcontext\u001b[39m.\u001b[39;49moptions),\n\u001b[1;32m    102\u001b[0m         context\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mcontext,\n\u001b[1;32m    103\u001b[0m     )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/transport/_requests_basic.py:364\u001b[0m, in \u001b[0;36mRequestsTransport.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m     error \u001b[39m=\u001b[39m ServiceRequestError(err, error\u001b[39m=\u001b[39merr)\n\u001b[1;32m    363\u001b[0m \u001b[39mif\u001b[39;00m error:\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mraise\u001b[39;00m error\n\u001b[1;32m    365\u001b[0m \u001b[39mif\u001b[39;00m _is_rest(request):\n\u001b[1;32m    366\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mazure\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrest\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_requests_basic\u001b[39;00m \u001b[39mimport\u001b[39;00m RestRequestsTransportResponse\n",
            "\u001b[0;31mServiceResponseError\u001b[0m: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ".."
        }
      ],
      "execution_count": 62,
      "metadata": {
        "gather": {
          "logged": 1667385183402
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Optionally, you can change the values in the `sample-data.json` file to try and get a different prediction."
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## List endpoints\n",
        "\n",
        "Although you can view all endpoints in the Studio, you can also list all endpoints using the SDK:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoints = ml_client.online_endpoints.list()\n",
        "for endp in endpoints:\n",
        "    print(endp.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "endpoint-07251143861665\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1690287268768
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Get endpoint details\n",
        "\n",
        "If you want more information about a specific endpoint, you can explore the details using the SDK too."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the details for online endpoint\n",
        "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
        "\n",
        "# existing traffic details\n",
        "print(endpoint.traffic)\n",
        "\n",
        "# Get the scoring URI\n",
        "print(endpoint.scoring_uri)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'blue': 0}\nhttps://endpoint-06271304571648.australiaeast.inference.ml.azure.com/score\n"
        }
      ],
      "execution_count": 64,
      "metadata": {
        "gather": {
          "logged": 1667395538913
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Delete the endpoint and deployment\n",
        "\n",
        "As an endpoint is always available, it can't be paused to save costs. To avoid unnecessary costs, delete the endpoint."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "<azure.core.polling._poller.LROPoller at 0x7f3f18d3b5b0>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ".."
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1667395549933
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}