{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Tune hyperparameters with a sweep job\n",
        "\n",
        "There are many machine learning algorithms that require hyperparameters (parameter values that influence training, but can't be determined from the training data itself). For example, when training a logistic regression model, you can use a regularization rate hyperparameter to counteract bias in the model; or when training a convolutional neural network, you can use hyperparameters like learning rate and batch size to control how weights are adjusted and how many data items are processed in a mini-batch respectively. The choice of hyperparameter values can significantly affect the performance of a trained model, or the time taken to train it; and often you need to try multiple combinations to find the optimal solution. \n",
        "\n",
        "## Before you start\n",
        "\n",
        "You'll need the latest version of the  **azureml-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
        "\n",
        "> **Note**:\n",
        "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pip show azure-ai-ml"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Name: azure-ai-ml\r\nVersion: 1.5.0\r\nSummary: Microsoft Azure Machine Learning Client Library for Python\r\nHome-page: https://github.com/Azure/azure-sdk-for-python\r\nAuthor: Microsoft Corporation\r\nAuthor-email: azuresdkengsysadmins@microsoft.com\r\nLicense: MIT License\r\nLocation: /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages\r\nRequires: azure-common, azure-core, azure-mgmt-core, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, opencensus-ext-azure, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\r\nRequired-by: \r\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1687848222567
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1687848229410
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1687848232503
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create the training script\n",
        "Hyperparameter tuning is ideal when you want to train a machine learning models but vary the input parameters. You'll need to create a training script that expects an input parameter representing one of the algorithm's hyperparameters.\n",
        "\n",
        "Run the following cells to create the **src** folder and the training script.\n",
        "\n",
        "Note that the training script expects two input parameters:\n",
        "\n",
        "- `--training_data` which expects a string. You'll specify the path to a registered data asset as the input training data.\n",
        "- `--reg_rate` which expects a number, but has a default value of `0.01`. You'll use this input parameter for hyperparameter tuning."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "src folder created\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1687848235783
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/train.py\n",
        "# import libraries\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test = split_data(df)\n",
        "\n",
        "    # train model\n",
        "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # evaluate model\n",
        "    eval_model(model, X_test, y_test)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    print(\"Reading data...\")\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# function that splits the data\n",
        "def split_data(df):\n",
        "    print(\"Splitting data...\")\n",
        "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
        "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# function that trains the model\n",
        "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
        "    mlflow.log_param(\"Regularization rate\", reg_rate)\n",
        "    print(\"Training model...\")\n",
        "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    return model\n",
        "\n",
        "# function that evaluates the model\n",
        "def eval_model(model, X_test, y_test):\n",
        "    # calculate accuracy\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        "    mlflow.log_metric(\"Accuracy\", acc)\n",
        "\n",
        "    # calculate AUC\n",
        "    y_scores = model.predict_proba(X_test)\n",
        "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "    print('AUC: ' + str(auc))\n",
        "    mlflow.log_metric(\"AUC\", auc)\n",
        "\n",
        "    # plot ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    # Plot the diagonal 50% line\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    # Plot the FPR and TPR achieved by our model\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.savefig(\"ROC-Curve.png\")\n",
        "    mlflow.log_artifact(\"ROC-Curve.png\")    \n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
        "                        type=float, default=0.01)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing src/train.py\n"
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Configure and run a command job\n",
        "\n",
        "Run the cell below to train a classification model to predict diabetes. The model is trained by running the **train\\.py** script that can be found in the **src** folder. It uses the registered `diabetes-data` data asset as the training data. \n",
        "\n",
        "- `code`: specifies the folder that includes the script to run.\n",
        "- `command`: specifies what to run exactly.\n",
        "- `environment`: specifies the necessary packages to be installed on the compute before running the command.\n",
        "- `compute`: specifies the compute to use to run the command.\n",
        "- `display_name`: the name of the individual job.\n",
        "- `experiment_name`: the name of the experiment the job belongs to.\n",
        "\n",
        "Note that the command job only runs the training script once, with a regularization rate of `0.1`. Before you run a sweep job to tune hyperparameters, it's a best practice to test whether your script works as expected with a command job."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command, Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# configure job\n",
        "\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python train.py --training_data ${{inputs.diabetes_data}} --reg_rate ${{inputs.reg_rate}}\",\n",
        "    inputs={\n",
        "        \"diabetes_data\": Input(\n",
        "            type=AssetTypes.URI_FILE, \n",
        "            path=\"azureml:diabetes-data:1\"\n",
        "            ),\n",
        "        \"reg_rate\": 0.01,\n",
        "    },\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"farbodtaymouri1\",\n",
        "    display_name=\"diabetes-train-mlflow\",\n",
        "    experiment_name=\"diabetes-training\", \n",
        "    tags={\"model_type\": \"LogisticRegression\"}\n",
        "    )\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Monitor your job at https://ml.azure.com/runs/helpful_pencil_62ds66wytk?wsid=/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourcegroups/mlcertificate/workspaces/ft_ml&tid=71f8feea-4caa-4230-a785-dca61147bceb\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1667592538771
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Dataset\n",
        "import mltable\n",
        "\n",
        "registered_data_asset = ml_client.data.get(name='diabetes-local', version=1)\n",
        "tbl = mltable.load(f\"azureml:/{registered_data_asset.id}\")\n",
        "df = tbl.to_pandas_dataframe()\n",
        "df.head(5)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting mltable\n  Downloading mltable-1.4.1-py3-none-any.whl (179 kB)\n\u001b[K     |████████████████████████████████| 179 kB 7.8 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: pyyaml<7.0.0,>=5.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mltable) (6.0)\nRequirement already satisfied: msrest>=0.6.18 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mltable) (0.7.1)\nRequirement already satisfied: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mltable) (38.0.4)\nRequirement already satisfied: azure-core!=1.22.0,<2.0.0,>=1.8.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mltable) (1.26.3)\nRequirement already satisfied: PyJWT<3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mltable) (2.4.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mltable) (2.8.2)\nRequirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mltable) (1.3.2)\nCollecting azureml-dataprep[parquet]<4.12.0a,>=4.11.1\n  Downloading azureml_dataprep-4.11.3-py3-none-any.whl (38.2 MB)\n\u001b[K     |████████████████████████████████| 38.2 MB 21.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mltable) (4.17.3)\nRequirement already satisfied: pytz in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mltable) (2022.5)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.6.18->mltable) (2022.9.24)\nRequirement already satisfied: isodate>=0.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.6.18->mltable) (0.6.1)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.6.18->mltable) (1.3.1)\nRequirement already satisfied: requests~=2.16 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.6.18->mltable) (2.28.2)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->mltable) (1.15.1)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-core!=1.22.0,<2.0.0,>=1.8.0->mltable) (1.16.0)\nRequirement already satisfied: typing-extensions>=4.0.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-core!=1.22.0,<2.0.0,>=1.8.0->mltable) (4.4.0)\nRequirement already satisfied: cloudpickle<3.0.0,>=1.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azureml-dataprep[parquet]<4.12.0a,>=4.11.1->mltable) (1.6.0)\nRequirement already satisfied: azure-identity>=1.7.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azureml-dataprep[parquet]<4.12.0a,>=4.11.1->mltable) (1.7.0)\nRequirement already satisfied: dotnetcore2<4.0.0,>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azureml-dataprep[parquet]<4.12.0a,>=4.11.1->mltable) (3.1.23)\nRequirement already satisfied: azureml-dataprep-native<39.0.0,>=38.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azureml-dataprep[parquet]<4.12.0a,>=4.11.1->mltable) (38.0.0)\nCollecting azureml-dataprep-rslex~=2.18.3dev0\n  Downloading azureml_dataprep_rslex-2.18.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.0 MB)\n\u001b[K     |████████████████████████████████| 22.0 MB 80.0 MB/s eta 0:00:01    |████████▉                       | 6.1 MB 80.0 MB/s eta 0:00:01 MB 80.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: pyarrow<=9.0.0,>=0.17.0; extra == \"parquet\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azureml-dataprep[parquet]<4.12.0a,>=4.11.1->mltable) (9.0.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->mltable) (0.19.3)\nRequirement already satisfied: attrs>=17.4.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->mltable) (22.2.0)\nRequirement already satisfied: importlib-resources>=1.4.0; python_version < \"3.9\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->mltable) (5.10.2)\nRequirement already satisfied: pkgutil-resolve-name>=1.3.10; python_version < \"3.9\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->mltable) (1.3.10)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->mltable) (3.2.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests~=2.16->msrest>=0.6.18->mltable) (3.0.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests~=2.16->msrest>=0.6.18->mltable) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests~=2.16->msrest>=0.6.18->mltable) (3.4)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from cffi>=1.12->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->mltable) (2.21)\nRequirement already satisfied: msal-extensions~=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity>=1.7.0->azureml-dataprep[parquet]<4.12.0a,>=4.11.1->mltable) (0.3.1)\nRequirement already satisfied: msal<2.0.0,>=1.12.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity>=1.7.0->azureml-dataprep[parquet]<4.12.0a,>=4.11.1->mltable) (1.21.0)\nRequirement already satisfied: distro>=1.2.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from dotnetcore2<4.0.0,>=3.0.0->azureml-dataprep[parquet]<4.12.0a,>=4.11.1->mltable) (1.8.0)\nRequirement already satisfied: numpy>=1.16.6 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pyarrow<=9.0.0,>=0.17.0; extra == \"parquet\"->azureml-dataprep[parquet]<4.12.0a,>=4.11.1->mltable) (1.21.6)\nRequirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from importlib-resources>=1.4.0; python_version < \"3.9\"->jsonschema<5.0.0,>=4.0.0->mltable) (3.12.0)\nRequirement already satisfied: portalocker<3,>=1.0; python_version >= \"3.5\" and platform_system != \"Windows\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msal-extensions~=0.3.0->azure-identity>=1.7.0->azureml-dataprep[parquet]<4.12.0a,>=4.11.1->mltable) (2.7.0)\n\u001b[31mERROR: azureml-dataset-runtime 1.49.0 has requirement azureml-dataprep<4.10.0a,>=4.9.0a, but you'll have azureml-dataprep 4.11.3 which is incompatible.\u001b[0m\n\u001b[31mERROR: azureml-automl-runtime 1.49.0 has requirement protobuf<=3.20.1, but you'll have protobuf 4.23.2 which is incompatible.\u001b[0m\nInstalling collected packages: azureml-dataprep-rslex, azureml-dataprep, mltable\n  Attempting uninstall: azureml-dataprep-rslex\n    Found existing installation: azureml-dataprep-rslex 2.16.1\n    Uninstalling azureml-dataprep-rslex-2.16.1:\n      Successfully uninstalled azureml-dataprep-rslex-2.16.1\n  Attempting uninstall: azureml-dataprep\n    Found existing installation: azureml-dataprep 4.9.1\n    Uninstalling azureml-dataprep-4.9.1:\n      Successfully uninstalled azureml-dataprep-4.9.1\nSuccessfully installed azureml-dataprep-4.11.3 azureml-dataprep-rslex-2.18.3 mltable-1.4.1\n"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Can only load MLTable type asset",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[32], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmltable\u001b[39;00m\n\u001b[1;32m      5\u001b[0m registered_data_asset \u001b[39m=\u001b[39m ml_client\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mget(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdiabetes-local\u001b[39m\u001b[39m'\u001b[39m, version\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m tbl \u001b[39m=\u001b[39m mltable\u001b[39m.\u001b[39;49mload(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mazureml:/\u001b[39;49m\u001b[39m{\u001b[39;49;00mregistered_data_asset\u001b[39m.\u001b[39;49mid\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m df \u001b[39m=\u001b[39m tbl\u001b[39m.\u001b[39mto_pandas_dataframe()\n\u001b[1;32m      8\u001b[0m df\u001b[39m.\u001b[39mhead(\u001b[39m5\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azureml/dataprep/api/_loggerfactory.py:273\u001b[0m, in \u001b[0;36mtrack.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[39mwith\u001b[39;00m _LoggerFactory\u001b[39m.\u001b[39mtrack_activity(logger, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, DEFAULT_ACTIVITY_TYPE, custom_dimensions) \u001b[39mas\u001b[39;00m activityLogger:\n\u001b[1;32m    272\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    274\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    275\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(activityLogger, ACTIVITY_INFO_KEY) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, ERROR_CODE_KEY):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mltable/mltable.py:431\u001b[0m, in \u001b[0;36mload\u001b[0;34m(uri, storage_options)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39m@track\u001b[39m(_get_logger, custom_dimensions\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mapp_name\u001b[39m\u001b[39m'\u001b[39m: _APP_NAME})\n\u001b[1;32m    390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(uri, storage_options: \u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    391\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[39m    Loads the MLTable file (YAML) present at the given uri.\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39m    :rtype: mltable.MLTable\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m     \u001b[39mreturn\u001b[39;00m _load(uri, storage_options, \u001b[39mTrue\u001b[39;49;00m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azureml/dataprep/api/_loggerfactory.py:273\u001b[0m, in \u001b[0;36mtrack.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[39mwith\u001b[39;00m _LoggerFactory\u001b[39m.\u001b[39mtrack_activity(logger, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, DEFAULT_ACTIVITY_TYPE, custom_dimensions) \u001b[39mas\u001b[39;00m activityLogger:\n\u001b[1;32m    272\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    274\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    275\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(activityLogger, ACTIVITY_INFO_KEY) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, ERROR_CODE_KEY):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mltable/mltable.py:466\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(uri, storage_options, enable_validate)\u001b[0m\n\u001b[1;32m    464\u001b[0m     base_path \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[39melif\u001b[39;00m path_type \u001b[39m==\u001b[39m _PathType\u001b[39m.\u001b[39mdata_asset_uri:\n\u001b[0;32m--> 466\u001b[0m     mltable_dict \u001b[39m=\u001b[39m _load_mltable_from_data_asset_uri(\n\u001b[1;32m    467\u001b[0m         match, storage_options, enable_validate)\n\u001b[1;32m    468\u001b[0m     \u001b[39m# path has been mapped to absolute path in _load_mltable_from_data_asset_uri\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     base_path \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mltable/mltable.py:373\u001b[0m, in \u001b[0;36m_load_mltable_from_data_asset_uri\u001b[0;34m(asset_uri_match, storage_options, enable_validation)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39mif\u001b[39;00m is_v2:\n\u001b[1;32m    372\u001b[0m     \u001b[39mif\u001b[39;00m data_asset\u001b[39m.\u001b[39mdata_version\u001b[39m.\u001b[39mdata_type \u001b[39m!=\u001b[39m _APP_NAME:\n\u001b[0;32m--> 373\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCan only load MLTable type asset\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    374\u001b[0m     local_path \u001b[39m=\u001b[39m _download_mltable_yaml(data_asset\u001b[39m.\u001b[39mdata_version\u001b[39m.\u001b[39mdata_uri)\n\u001b[1;32m    375\u001b[0m     mltable_dict \u001b[39m=\u001b[39m _read_yaml(local_path)\n",
            "\u001b[0;31mValueError\u001b[0m: Can only load MLTable type asset"
          ]
        }
      ],
      "execution_count": 32,
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Define the search space\n",
        "\n",
        "When your command job has completed successfully, you can configure and run a sweep job. \n",
        "\n",
        "First, you'll need to specify the search space for your hyperparameter. To train three models, each with a different regularization rate (`0.01`, `0.1`, or `1`), you can define the search space with a `Choice` hyperparameter. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.sweep import Choice\n",
        "\n",
        "command_job_for_sweep = job(\n",
        "    reg_rate=Choice(values=[0.01, 0.1, 1]),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667592546442
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Configure and submit the sweep job\n",
        "\n",
        "You'll use the sweep function to do hyperparameter tuning on your training script. To configure a sweep job, you'll need to configure the following:\n",
        "\n",
        "- `compute`: Name of the compute target to execute the job on.\n",
        "- `sampling_algorithm`: The hyperparameter sampling algorithm to use over the search space. Allowed values are `random`, `grid` and `bayesian`.\n",
        "- `primary_metric`: The name of the primary metric reported by each trial job. The metric must be logged in the user's training script using `mlflow.log_metric()` with the same corresponding metric name.\n",
        "- `goal`: The optimization goal of the `primary_metric`. The allowed values are `maximize` and `minimize`.\n",
        "- `limits`: Limits for the sweep job. For example, the maximum amount of trials or models you want to train.\n",
        "\n",
        "Note that the command job is used as the base for the sweep job. The configuration for the command job will be reused by the sweep job."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the sweep parameter to obtain the sweep_job\n",
        "sweep_job = command_job_for_sweep.sweep(\n",
        "    compute=\"aml-cluster\",\n",
        "    sampling_algorithm=\"grid\",\n",
        "    primary_metric=\"training_accuracy_score\",\n",
        "    goal=\"Maximize\",\n",
        ")\n",
        "\n",
        "# set the name of the sweep job experiment\n",
        "sweep_job.experiment_name=\"sweep-diabetes\"\n",
        "\n",
        "# define the limits for this sweep\n",
        "sweep_job.set_limits(max_total_trials=4, max_concurrent_trials=2, timeout=7200)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667592681475
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Run the following cell to submit the sweep job."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
        "aml_url = returned_sweep_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667592716881
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "When the job is completed, navigate to the job overview. The **Trials** tab will show all models that have been trained and how the `Accuracy` score differs for each regularization rate value you tried."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}