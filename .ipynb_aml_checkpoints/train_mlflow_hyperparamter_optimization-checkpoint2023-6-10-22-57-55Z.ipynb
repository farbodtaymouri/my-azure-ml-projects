{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Installing the the required library\n",
        "!pip install azure-ai-ml\n",
        "!pip show azure-ai-ml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1688970400645
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connecting to the workspace\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1689022887800
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to azure services (worksopace)\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1689022895597
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a data asset\r\n",
        "from azure.ai.ml.entities import Data\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "my_path = './data/diabetes.csv'\r\n",
        "\r\n",
        "my_data = Data(\r\n",
        "    path=my_path,\r\n",
        "    type=AssetTypes.URI_FILE,\r\n",
        "    description=\"Data asset pointing to a local file, automatically uploaded to the default datastore\",\r\n",
        "    name=\"my-diabetes-local\"\r\n",
        ")\r\n",
        "\r\n",
        "ml_client.data.create_or_update(my_data)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "Data({'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'name': 'my-diabetes-local', 'description': 'Data asset pointing to a local file, automatically uploaded to the default datastore', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourceGroups/mlcertificate/providers/Microsoft.MachineLearningServices/workspaces/ft_ml/data/my-diabetes-local/versions/2', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/farbodtaymouri1/code/Users/farbodtaymouri/my-azure-ml-projects', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fc3bdc5b6d0>, 'serialize': <msrest.serialization.Serializer object at 0x7fc3bdc5b130>, 'version': '2', 'latest_version': None, 'path': 'azureml://subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourcegroups/mlcertificate/workspaces/ft_ml/datastores/workspaceblobstore/paths/LocalUpload/d52d15a0d7d1e95b90a03f146099424a/diabetes.csv', 'datastore': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1689022905179
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a source directory\n",
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "src folder created\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1688975624581
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/train-model-mlflow.py\n",
        "# import libraries\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from mlflow.models import infer_signature\n",
        "\n",
        "\n",
        "\n",
        "from mlflow.pyfunc import PythonModel, PythonModelContext\n",
        "# https://learn.microsoft.com/en-us/azure/machine-learning/how-to-log-mlflow-models?view=azureml-api-2&tabs=wrapper#logging-custom-models\n",
        "class ModelWrapper(PythonModel):\n",
        "    def __init__(self, model):\n",
        "        self._model = model\n",
        "\n",
        "    def predict(self, context: PythonModelContext, data):\n",
        "        # You don't have to keep the semantic meaning of `predict`. You can use here model.recommend(), model.forecast(), etc\n",
        "        return self._model.predict_proba(data)\n",
        "\n",
        "    # You can even add extra functions if you need to. Since the model is serialized,\n",
        "    # all of them will be available when you load your model back.\n",
        "    def predict_batch(self, data):\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test = split_data(df)\n",
        "\n",
        "    # train model\n",
        "    model = train_model(args.n_estimators, args.max_depth, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # evaluate model\n",
        "    eval_model(model, X_test, y_test)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    print(\"Reading data...\")\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# function that splits the data\n",
        "def split_data(df):\n",
        "    print(\"Splitting data...\")\n",
        "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
        "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# function that trains the model\n",
        "def train_model(n_estimators, max_depth, X_train, X_test, y_train, y_test):\n",
        "\n",
        "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "    mlflow.log_param(\"max_depth\", max_depth)\n",
        "\n",
        "\n",
        "    clf = RandomForestClassifier(max_depth = max_depth, n_estimators = n_estimators, random_state=0)\n",
        "    model = clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    # mlflow.log_param(\"Regularization rate\", reg_rate)\n",
        "    # print(\"Training model...\")\n",
        "    # model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    y_probs = model.predict_proba(X_test)\n",
        "\n",
        "    #Logging the model artifact\n",
        "    signature = infer_signature(X_test, y_probs)\n",
        "    mlflow.pyfunc.log_model(\"classifier\", \n",
        "                        python_model=ModelWrapper(model),\n",
        "                        signature=signature)\n",
        "    \n",
        "\n",
        "    return model\n",
        "\n",
        "# function that evaluates the model\n",
        "def eval_model(model, X_test, y_test):\n",
        "    # calculate accuracy\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        "    mlflow.log_metric(\"Accuracy\", acc)\n",
        "\n",
        "    # calculate AUC\n",
        "    y_scores = model.predict_proba(X_test)\n",
        "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "    print('AUC: ' + str(auc))\n",
        "    mlflow.log_metric(\"AUC\", auc)\n",
        "\n",
        "    # plot ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    # Plot the diagonal 50% line\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    # Plot the FPR and TPR achieved by our model\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.savefig(\"ROC-Curve.png\")\n",
        "    mlflow.log_artifact(\"ROC-Curve.png\")    \n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--n_estimators\", dest='n_estimators',\n",
        "                        type=int, default=10)\n",
        "    parser.add_argument(\"--max_depth\", dest='max_depth',\n",
        "                        type=int, default=3)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting src/train-model-mlflow.py\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the script as a commnd job with taking inputs as arga\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the script as command\r\n",
        "from azure.ai.ml import command\r\n",
        "from azure.ai.ml import command, Input\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "# configure job\r\n",
        "\r\n",
        "job = command(\r\n",
        "    code=\"./src\",\r\n",
        "    command=\"python train-model-mlflow.py --training_data ${{inputs.diabetes_data}} --n_estimators ${{inputs.n_estimators}} --max_depth ${{inputs.max_depth}}\",\r\n",
        "    inputs={\r\n",
        "    \"diabetes_data\": Input(\r\n",
        "        type=AssetTypes.URI_FILE, \r\n",
        "        path=\"azureml:my-diabetes-local:1\"\r\n",
        "        ),\r\n",
        "    \"n_estimators\": 5,\r\n",
        "    \"max_depth\":2,\r\n",
        "    },\r\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\r\n",
        "    compute=\"farbodtaymouri1\",\r\n",
        "    display_name=\"diabetes-train-mlflow\",\r\n",
        "    experiment_name=\"diabetes-training2\", \r\n",
        "    tags={\"model_type\": \"RandomForest\"}\r\n",
        "    )\r\n",
        "\r\n",
        "# submit job if you want to run it\r\n",
        "returned_job = ml_client.create_or_update(job)\r\n",
        "aml_url = returned_job.studio_url\r\n",
        "print(\"Monitor your job at\", aml_url)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1689023279213
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparamter tuning"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the variables and values for selection\r\n",
        "from azure.ai.ml.sweep import Choice\r\n",
        "\r\n",
        "# Note that such values can be initiated during creating the initial job in the above cell as well\r\n",
        "command_job_for_sweep = job(\r\n",
        "    n_estimators=Choice(values=[5, 10, 20]),\r\n",
        "    max_depth = Choice(values=[2, 3, 5]),\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1689023294029
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the sweep parameter to obtain the sweep_job\r\n",
        "sweep_job = command_job_for_sweep.sweep(\r\n",
        "    compute=\"farbodtaymouri1\",\r\n",
        "    sampling_algorithm=\"bayesian\",\r\n",
        "    primary_metric=\"training_accuracy_score\",\r\n",
        "    goal=\"Maximize\",\r\n",
        ")\r\n",
        "\r\n",
        "# set the name of the sweep job experiment\r\n",
        "sweep_job.experiment_name=\"RF-sweep-diabetes\"\r\n",
        "\r\n",
        "# define the limits for this sweep\r\n",
        "sweep_job.set_limits(max_total_trials=4, max_concurrent_trials=2, timeout=7200)"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1689026274502
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(command_job_for_sweep.sweep )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Help on method sweep in module azure.ai.ml.entities._builders.command:\n\nsweep(*, primary_metric: str, goal: str, sampling_algorithm: str = 'random', compute: Optional[str] = None, max_concurrent_trials: Optional[int] = None, max_total_trials: Optional[int] = None, timeout: Optional[int] = None, trial_timeout: Optional[int] = None, early_termination_policy: Union[azure.ai.ml.entities._job.sweep.early_termination_policy.EarlyTerminationPolicy, str, NoneType] = None, search_space: Optional[Dict[str, Union[azure.ai.ml.entities._job.sweep.search_space.Choice, azure.ai.ml.entities._job.sweep.search_space.LogNormal, azure.ai.ml.entities._job.sweep.search_space.LogUniform, azure.ai.ml.entities._job.sweep.search_space.Normal, azure.ai.ml.entities._job.sweep.search_space.QLogNormal, azure.ai.ml.entities._job.sweep.search_space.QLogUniform, azure.ai.ml.entities._job.sweep.search_space.QNormal, azure.ai.ml.entities._job.sweep.search_space.QUniform, azure.ai.ml.entities._job.sweep.search_space.Randint, azure.ai.ml.entities._job.sweep.search_space.Uniform]]] = None, identity: Union[azure.ai.ml.entities._credentials.ManagedIdentityConfiguration, azure.ai.ml.entities._credentials.AmlTokenConfiguration, azure.ai.ml.entities._credentials.UserIdentityConfiguration, NoneType] = None, queue_settings: Optional[azure.ai.ml.entities._job.queue_settings.QueueSettings] = None, job_tier: Optional[str] = None, priority: Optional[str] = None) -> azure.ai.ml.entities._builders.sweep.Sweep method of azure.ai.ml.entities._builders.command.Command instance\n    Turn the command into a sweep node with extra sweep run setting. The command component in current Command\n    node will be used as its trial component. A command node can sweep for multiple times, and the generated sweep\n    node will share the same trial component.\n    \n    :param primary_metric: primary metric of the sweep objective, AUC e.g. The metric must be logged in running\n        the trial component.\n    :type primary_metric: str\n    :param goal: goal of the sweep objective.\n    :type goal: str, valid values: maximize or minimize\n    :param sampling_algorithm: sampling algorithm to sample inside search space. Defaults to \"random\"\n    :type sampling_algorithm: str, valid values: random, grid or bayesian\n    :param compute: target compute to run the node. If not specified, compute of current node will be used.\n    :type compute: str\n    :param max_total_trials: maximum trials to run, will overwrite value in limits\n    :type max_total_trials: int\n    :param max_concurrent_trials: Sweep Job max concurrent trials.\n    :type max_concurrent_trials: int\n    :param max_total_trials: Sweep Job max total trials.\n    :type max_total_trials: int\n    :param timeout: The max run duration in seconds, after which the job will be cancelled.\n    :type timeout: int\n    :param trial_timeout: Sweep Job Trial timeout value in seconds.\n    :type trial_timeout: int\n    :param early_termination_policy: early termination policy of the sweep node:\n    :type early_termination_policy: Union[EarlyTerminationPolicy, str], valid values: bandit, median_stopping\n        or truncation_selection.\n    :param identity: Identity that training job will use while running on compute.\n    :type identity: Union[\n        ManagedIdentityConfiguration,\n        AmlTokenConfiguration,\n        UserIdentityConfiguration]\n    :param queue_settings: Queue settings for the job.\n    :type queue_settings: QueueSettings\n    :param job_tier: **Experimental** determines the job tier.\n    :type job_tier: str\n    :param priority: **Experimental** controls the priority on the compute.\n    :type priority: str\n    :return: A sweep node with component from current Command node as its trial component.\n    :rtype: Sweep\n\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1689023462911
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# returned_sweep_job = ml_client.create_or_update(sweep_job)\r\n",
        "# aml_url = returned_sweep_job.studio_url\r\n",
        "# print(\"Monitor your job at\", aml_url)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Monitor your job at https://ml.azure.com/runs/modest_basket_gc827bgs23?wsid=/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourcegroups/mlcertificate/workspaces/ft_ml&tid=71f8feea-4caa-4230-a785-dca61147bceb\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1689023586810
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://learn.microsoft.com/en-us/azure/machine-learning/how-to-train-tensorflow?view=azureml-api-2\r\n",
        "returned_sweep_job = ml_client.create_or_update(sweep_job)\r\n",
        "\r\n",
        "# stream the output and wait until the job is finished\r\n",
        "ml_client.jobs.stream(returned_sweep_job.name)\r\n",
        "\r\n",
        "# refresh the latest status of the job after streaming\r\n",
        "returned_sweep_job = ml_client.jobs.get(name=returned_sweep_job.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: willing_owl_dxsmksgy9v\nWeb View: https://ml.azure.com/runs/willing_owl_dxsmksgy9v?wsid=/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourcegroups/mlcertificate/workspaces/ft_ml\n\nExecution Summary\n=================\nRunId: willing_owl_dxsmksgy9v\nWeb View: https://ml.azure.com/runs/willing_owl_dxsmksgy9v?wsid=/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourcegroups/mlcertificate/workspaces/ft_ml\n\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1689026587731
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "returned_sweep_job.properties[\"best_child_run_id\"]"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'best_child_run_id'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mreturned_sweep_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproperties\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_child_run_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'best_child_run_id'"
          ]
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1689028769270
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}