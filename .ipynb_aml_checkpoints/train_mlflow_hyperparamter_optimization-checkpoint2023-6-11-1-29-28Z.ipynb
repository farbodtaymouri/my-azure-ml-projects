{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Installing the the required library\n",
        "!pip install azure-ai-ml\n",
        "!pip show azure-ai-ml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1688970400645
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connecting to the workspace\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1689037024983
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to azure services (worksopace)\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1689037027203
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a data asset\r\n",
        "from azure.ai.ml.entities import Data\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "my_path = './data/diabetes.csv'\r\n",
        "\r\n",
        "my_data = Data(\r\n",
        "    path=my_path,\r\n",
        "    type=AssetTypes.URI_FILE,\r\n",
        "    description=\"Data asset pointing to a local file, automatically uploaded to the default datastore\",\r\n",
        "    name=\"my-diabetes-local\"\r\n",
        ")\r\n",
        "\r\n",
        "ml_client.data.create_or_update(my_data)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "Data({'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'name': 'my-diabetes-local', 'description': 'Data asset pointing to a local file, automatically uploaded to the default datastore', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourceGroups/mlcertificate/providers/Microsoft.MachineLearningServices/workspaces/ft_ml/data/my-diabetes-local/versions/3', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/farbodtaymouri1/code/Users/farbodtaymouri/my-azure-ml-projects', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f46b6fd8250>, 'serialize': <msrest.serialization.Serializer object at 0x7f46b6fdbf40>, 'version': '3', 'latest_version': None, 'path': 'azureml://subscriptions/2a21ade8-9d70-4d5a-a619-083b264d1d56/resourcegroups/mlcertificate/workspaces/ft_ml/datastores/workspaceblobstore/paths/LocalUpload/d52d15a0d7d1e95b90a03f146099424a/diabetes.csv', 'datastore': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1689037031330
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a source directory\n",
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "src folder created\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1688975624581
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/train-model-mlflow.py\n",
        "# import libraries\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from mlflow.models import infer_signature\n",
        "\n",
        "\n",
        "\n",
        "from mlflow.pyfunc import PythonModel, PythonModelContext\n",
        "# https://learn.microsoft.com/en-us/azure/machine-learning/how-to-log-mlflow-models?view=azureml-api-2&tabs=wrapper#logging-custom-models\n",
        "class ModelWrapper(PythonModel):\n",
        "    def __init__(self, model):\n",
        "        self._model = model\n",
        "\n",
        "    def predict(self, context: PythonModelContext, data):\n",
        "        # You don't have to keep the semantic meaning of `predict`. You can use here model.recommend(), model.forecast(), etc\n",
        "        return self._model.predict_proba(data)\n",
        "\n",
        "    # You can even add extra functions if you need to. Since the model is serialized,\n",
        "    # all of them will be available when you load your model back.\n",
        "    def predict_batch(self, data):\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test = split_data(df)\n",
        "\n",
        "    # train model\n",
        "    model = train_model(args.n_estimators, args.max_depth, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # evaluate model\n",
        "    eval_model(model, X_test, y_test)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    print(\"Reading data...\")\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# function that splits the data\n",
        "def split_data(df):\n",
        "    print(\"Splitting data...\")\n",
        "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
        "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# function that trains the model\n",
        "def train_model(n_estimators, max_depth, X_train, X_test, y_train, y_test):\n",
        "\n",
        "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "    mlflow.log_param(\"max_depth\", max_depth)\n",
        "\n",
        "\n",
        "    clf = RandomForestClassifier(max_depth = max_depth, n_estimators = n_estimators, random_state=0)\n",
        "    model = clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    # mlflow.log_param(\"Regularization rate\", reg_rate)\n",
        "    # print(\"Training model...\")\n",
        "    # model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    y_probs = model.predict_proba(X_test)\n",
        "\n",
        "    #Logging the model artifact\n",
        "    signature = infer_signature(X_test, y_probs)\n",
        "    mlflow.pyfunc.log_model(\"classifier\", \n",
        "                        python_model=ModelWrapper(model),\n",
        "                        signature=signature)\n",
        "    \n",
        "\n",
        "    return model\n",
        "\n",
        "# function that evaluates the model\n",
        "def eval_model(model, X_test, y_test):\n",
        "    # calculate accuracy\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        "    mlflow.log_metric(\"Accuracy\", acc)\n",
        "\n",
        "    # calculate AUC\n",
        "    y_scores = model.predict_proba(X_test)\n",
        "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "    print('AUC: ' + str(auc))\n",
        "    mlflow.log_metric(\"AUC\", auc)\n",
        "\n",
        "    # plot ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    # Plot the diagonal 50% line\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    # Plot the FPR and TPR achieved by our model\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.savefig(\"ROC-Curve.png\")\n",
        "    mlflow.log_artifact(\"ROC-Curve.png\")    \n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--n_estimators\", dest='n_estimators',\n",
        "                        type=int, default=10)\n",
        "    parser.add_argument(\"--max_depth\", dest='max_depth',\n",
        "                        type=int, default=3)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting src/train-model-mlflow.py\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the script as a commnd job with taking inputs as arga\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the script as command\r\n",
        "from azure.ai.ml import command\r\n",
        "from azure.ai.ml import command, Input\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "# configure job\r\n",
        "\r\n",
        "job = command(\r\n",
        "    code=\"./src\",\r\n",
        "    command=\"python train-model-mlflow.py --training_data ${{inputs.diabetes_data}} --n_estimators ${{inputs.n_estimators}} --max_depth ${{inputs.max_depth}}\",\r\n",
        "    inputs={\r\n",
        "    \"diabetes_data\": Input(\r\n",
        "        type=AssetTypes.URI_FILE, \r\n",
        "        path=\"azureml:my-diabetes-local:1\"\r\n",
        "        ),\r\n",
        "    \"n_estimators\": 5,\r\n",
        "    \"max_depth\":2,\r\n",
        "    },\r\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\r\n",
        "    compute=\"farbodtaymouri1\",\r\n",
        "    display_name=\"diabetes-train-mlflow\",\r\n",
        "    experiment_name=\"diabetes-training2\", \r\n",
        "    tags={\"model_type\": \"RandomForest\"}\r\n",
        "    )\r\n",
        "\r\n",
        "# submit job if you want to run it\r\n",
        "returned_job = ml_client.create_or_update(job)\r\n",
        "aml_url = returned_job.studio_url\r\n",
        "print(\"Monitor your job at\", aml_url)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1689037041030
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparamter tuning"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the variables and values for selection\r\n",
        "from azure.ai.ml.sweep import Choice\r\n",
        "\r\n",
        "# Note that such values can be initiated during creating the initial job in the above cell as well\r\n",
        "command_job_for_sweep = job(\r\n",
        "    n_estimators=Choice(values=[5, 10, 20]),\r\n",
        "    max_depth = Choice(values=[2, 3, 5]),\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1689037048963
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the sweep parameter to obtain the sweep_job\r\n",
        "sweep_job = command_job_for_sweep.sweep(\r\n",
        "    compute=\"farbodtaymouri1\",\r\n",
        "    sampling_algorithm=\"bayesian\",\r\n",
        "    primary_metric=\"training_accuracy_score\",\r\n",
        "    goal=\"Maximize\",\r\n",
        ")\r\n",
        "\r\n",
        "# set the name of the sweep job experiment\r\n",
        "sweep_job.experiment_name=\"RF-sweep-diabetes\"\r\n",
        "\r\n",
        "# define the limits for this sweep\r\n",
        "sweep_job.set_limits(max_total_trials=4, max_concurrent_trials=2, timeout=7200)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1689037057306
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# help(command_job_for_sweep.sweep )\r\n",
        "help(command)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Help on function command in module azure.ai.ml.entities._builders.command_func:\n\ncommand(*, name: Optional[str] = None, description: Optional[str] = None, tags: Optional[Dict] = None, properties: Optional[Dict] = None, display_name: Optional[str] = None, command: Optional[str] = None, experiment_name: Optional[str] = None, environment: Union[str, azure.ai.ml.entities._assets.environment.Environment, NoneType] = None, environment_variables: Optional[Dict] = None, distribution: Union[Dict, azure.ai.ml.entities._job.distribution.MpiDistribution, azure.ai.ml.entities._job.distribution.TensorFlowDistribution, azure.ai.ml.entities._job.distribution.PyTorchDistribution, NoneType] = None, compute: Optional[str] = None, inputs: Optional[Dict] = None, outputs: Optional[Dict] = None, instance_count: Optional[int] = None, instance_type: Optional[str] = None, locations: Optional[List[str]] = None, docker_args: Optional[str] = None, shm_size: Optional[str] = None, timeout: Optional[int] = None, code: Union[os.PathLike, str, NoneType] = None, identity: Union[azure.ai.ml.entities._credentials.ManagedIdentityConfiguration, azure.ai.ml.entities._credentials.AmlTokenConfiguration, azure.ai.ml.entities._credentials.UserIdentityConfiguration, NoneType] = None, is_deterministic: bool = True, services: Optional[Dict[str, Union[azure.ai.ml.entities._job.job_service.JobService, azure.ai.ml.entities._job.job_service.JupyterLabJobService, azure.ai.ml.entities._job.job_service.SshJobService, azure.ai.ml.entities._job.job_service.TensorBoardJobService, azure.ai.ml.entities._job.job_service.VsCodeJobService]]] = None, job_tier: Optional[str] = None, priority: Optional[str] = None, **kwargs) -> azure.ai.ml.entities._builders.command.Command\n    Create a Command object which can be used inside dsl.pipeline as a function and can also be created as a\n    standalone command job.\n    \n    :param name: Name of the command job or component created\n    :type name: str\n    :param description: a friendly description of the command\n    :type description: str\n    :param tags: Tags to be attached to this command\n    :type tags: Dict\n    :param properties: The asset property dictionary.\n    :type properties: dict[str, str]\n    :param display_name: a friendly name\n    :type display_name: str\n    :param experiment_name:  Name of the experiment the job will be created under,\n        if None is provided, default will be set to current directory name. Will be ignored as a pipeline step.\n    :type experiment_name: str\n    :param command: the command string that will be run\n    :type command: str\n    :param environment: the environment to use for this command\n    :type environment: Union[str, azure.ai.ml.entities.Environment]\n    :param environment_variables: environment variables to set on the compute before this command is executed\n    :type environment_variables: dict\n    :param distribution: the distribution mode to use for this command\n    :type distribution:\n        Union[Dict, azure.ai.ml.MpiDistribution, azure.ai.ml.TensorFlowDistribution, azure.ai.ml.PyTorchDistribution]\n    :param compute: the name of the compute where the command job is executed(\n        will not be used if the command is used as a component/function)\n    :type compute: str\n    :param inputs: a dict of inputs used by this command.\n    :type inputs: Dict\n    :param outputs: the outputs of this command\n    :type outputs: Dict\n    :param instance_count: Optional number of instances or nodes used by the compute target. Defaults to 1.\n    :vartype instance_count: int\n    :param instance_type: Optional type of VM used as supported by the compute target.\n    :vartype instance_type: str\n    :param locations: Optional list of locations where the job can run.\n    :vartype locations: List[str]\n    :param docker_args: Extra arguments to pass to the Docker run command. This would override any\n     parameters that have already been set by the system, or in this section. This parameter is only\n     supported for Azure ML compute types.\n    :vartype docker_args: str\n    :param shm_size: Size of the docker container's shared memory block. This should be in the\n     format of (number)(unit) where number as to be greater than 0 and the unit can be one of\n     b(bytes), k(kilobytes), m(megabytes), or g(gigabytes).\n    :vartype shm_size: str\n    :param timeout: The number in seconds, after which the job will be cancelled.\n    :vartype timeout: int\n    :param code: the code folder to run -- typically a local folder that will be uploaded as the job is submitted\n    :type code: Union[str, os.PathLike]\n    :param identity: Identity that training job will use while running on compute.\n    :type identity: Union[\n        azure.ai.ml.ManagedIdentityConfiguration,\n        azure.ai.ml.AmlTokenConfiguration]\n    :param is_deterministic: Specify whether the command will return same output given same input.\n        If a command (component) is deterministic, when use it as a node/step in a pipeline,\n        it will reuse results from a previous submitted job in current workspace which has same inputs and settings.\n        In this case, this step will not use any compute resource.\n        Default to be True, specify is_deterministic=False if you would like to avoid such reuse behavior.\n    :type is_deterministic: bool\n    :param services: Interactive services for the node. This is an experimental parameter, and may change at any time.\n        Please see https://aka.ms/azuremlexperimental for more information.\n    :type services: Dict[str, JobService]\n    :param job_tier: **Experimental** determines the job tier.\n    :type job_tier: str\n    :param priority: **Experimental** controls the priority on the compute.\n    :type priority: str\n\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1689037069037
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download best trial model output\r\n",
        "ml_client.jobs.download(returned_sweep_job.name, output_name=\"model\", download_path= '/model')\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The job status is not known: Running\n"
        }
      ],
      "execution_count": 62,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1689030588190
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}